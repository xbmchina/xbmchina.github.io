<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[线程之正确停止]]></title>
    <url>%2F2018%2F12%2F06%2F%E7%BA%BF%E7%A8%8B%E4%B9%8B%E6%AD%A3%E7%A1%AE%E5%81%9C%E6%AD%A2%2F</url>
    <content type="text"><![CDATA[单线程停止123456789101112131415161718192021222324252627282930313233343536public class ThreadStopSafeInterrupted &#123; public static void main(String[] args) throws InterruptedException &#123; Thread thread = new Thread() &#123; @Override public void run() &#123; while (true) &#123; // 使用中断机制，来终止线程 if (Thread.currentThread().isInterrupted()) &#123; System.out.println(&quot;Interrupted ...&quot;); break; &#125; try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; System.out.println(&quot;Interrupted When Sleep ...&quot;); // Thread.sleep()方法由于中断抛出异常。 // Java虚拟机会先将该线程的中断标识位清除，然后抛出InterruptedException， // 因为在发生InterruptedException异常的时候，会清除中断标记 // 如果不加处理，那么下一次循环开始的时候，就无法捕获这个异常。 // 故在异常处理中，再次设置中断标记位 Thread.currentThread().interrupt(); &#125; &#125; &#125; &#125;; // 开启线程 thread.start(); Thread.sleep(2000); thread.interrupt();//主线程发起中断 &#125; &#125; 线程池停止123456789101112131415/** * 停止线程池中的所有线程 */ private void stopDownloadThreadTask() &#123; try &#123; this.fixedThreadPool.shutdown();//尝试停止所有线程 if(!this.fixedThreadPool.awaitTermination(5 * 1000, TimeUnit.MILLISECONDS))&#123; this.fixedThreadPool.shutdownNow();//规定时间内还未停止，再次请求停止 &#125; &#125; catch (InterruptedException e) &#123; logger.error(&quot;awaitTermination interrupted: &quot; + e); this.fixedThreadPool.shutdownNow();//停不了就再停止一次。 &#125; &#125;]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue+axois]]></title>
    <url>%2F2018%2F12%2F06%2FVue-axois%2F</url>
    <content type="text"><![CDATA[简介axios基于 Promise 的 HTTP 请求客户端，可同时在浏览器和 node.js 中使用.详情可以参考官网。 常规使用request.js 12345678910111213141516171819202122232425262728293031323334353637383940import axios from &apos;axios&apos;// import store from &apos;@/store&apos;// 创建axios实例const service = axios.create(&#123; baseURL: &apos;&apos;, timeout: 15000 // 请求超时时间&#125;)// http request 请求拦截器，有token值则配置上token值// service.interceptors.request.use(// config =&gt; &#123;// if (token) &#123; // 每次发送请求之前判断是否存在token，如果存在，则统一在http请求的header都加上token，不用每次请求都手动添加了// config.headers.Authorization = token;// &#125;// return config;// &#125;,// err =&gt; &#123;// return Promise.reject(err);// &#125;);service.interceptors.response.use( function (response) &#123; //请求正常则返回 return Promise.resolve(response) &#125;, function (error) &#123; // 请求错误则向store commit这个状态变化 // const httpError = &#123; // hasError: true, // status: error.response.status, // statusText: error.response.statusText // &#125; // store.commit(&apos;ON_HTTP_ERROR&apos;, httpError) return Promise.reject(error) &#125;)export default service 新建一个api目录下login.js 123456789import request from &apos;@/utils/request&apos;export function getTest(params) &#123; return request(&#123; url: &apos;/u/register&apos;, method: &apos;get&apos;, params &#125;)&#125; 在登录组件login.vue中调用 1234567891011import &#123; getTest &#125; from &quot;@/api/login&quot;; methods: &#123; handleLogin() &#123; getTest(this.userame).then(response =&gt; &#123; alert(response.data); this.$store.dispatch(&apos;increment&apos;) &#125;) &#125; &#125; 一些坑跨域问题、post表单提交问题 ==&gt; 推荐这位大哥总结得还是不错的。]]></content>
      <categories>
        <category>Vue</category>
      </categories>
      <tags>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue-router总结]]></title>
    <url>%2F2018%2F12%2F06%2FVue-router%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[简介Vue Router 是 Vue.js 官方的路由管理器。它和 Vue.js 的核心深度集成，让构建单页面应用变得易如反掌。详情去看官网 基本概念 在【HTML】中使用 1234&lt;!-- 使用 router-link 组件来导航. --&gt;&lt;!-- 通过传入 `to` 属性指定链接. --&gt;&lt;!-- &lt;router-link&gt; 默认会被渲染成一个 `&lt;a&gt;` 标签 --&gt;&lt;router-link to=&quot;/foo&quot;&gt;Go to Foo&lt;/router-link&gt; 在【组件】中使用 12345678910111213141516// Home.vueexport default &#123; computed: &#123; username () &#123; // 我们很快就会看到 `params` 是什么 return this.$route.params.username &#125; &#125;, methods: &#123; goBack () &#123; window.history.length &gt; 1 ? this.$router.go(-1) : this.$router.push(&apos;/&apos;) &#125; &#125;&#125; 【动态路由】如果你想在路由上带参数，比如 /user/001 这种操作，可以参考 动态路由配置 【编程式导航】如果你想在js代码中实现跳转可以考虑使用编程式导航 【响应路由】例如：路径1：/user/001； 路径2：/user/002 。根据路由的不同复用原来的组件实例。这样子可以参考响应路由 【重定向路由】路由重定向 其他用法还是去官网自己看呗。 常规用法 1.在根目录新建一个router的文件夹，写一个index.js文件，内容如下 12345678910111213141516171819202122232425import Vue from &apos;vue&apos;import Router from &apos;vue-router&apos;// 0、加载相关依赖包Vue.use(Router)// 1、引入组件import Layout from &apos;@/views/layout/Layout&apos;// 2、定义路由export const constantRouterMap = [ &#123; path: &apos;/&apos;, component: Layout, children: [ &#123; path: &apos;/&apos;, component: () =&gt; import(&apos;@/views/login/index&apos;) &#125; ] &#125;]// 3、创建export default new Router(&#123; // mode: &apos;history&apos;, // require service support scrollBehavior: () =&gt; (&#123; y: 0 &#125;), routes: constantRouterMap &#125;) 2.在根目录中找到main.js，配置如下： 123456789101112import Vue from &apos;vue&apos;import App from &apos;./App.vue&apos;import router from &apos;./router&apos; //这里指向的是第一步中的index.jsimport store from &apos;./store&apos;Vue.config.productionTip = falsenew Vue(&#123; router, // 挂载到根实例 store, render: h =&gt; h(App),&#125;).$mount(&apos;#app&apos;) 3.在根目录中找到App.vue，配置标签添加如下： 12345678910111213&lt;template&gt; &lt;div id=&quot;app&quot;&gt; &lt;router-view/&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &apos;app&apos;&#125;&lt;/script&gt;]]></content>
      <categories>
        <category>Vue</category>
      </categories>
      <tags>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vuex总结]]></title>
    <url>%2F2018%2F12%2F06%2FVuex%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[简介简单来讲：共享的状态管理器，比如你想修改某些背景色，设备状态、cookie等信息的时候你可以考虑用它。其他的当跨页面共享数据的时候也可以考虑用它。其他的自己去看官网、所有的API参考 State单一状态树用来存储数据的，相当于一个变量（支持json对象、数组、字符串等），相当于数据源。 获取state中的状态值可以通过直接找或者通过getter方式 12345//方式一this.$store.state.test.phone.name//方式二this.$store.getters.phone Getter有时候我们需要从 store 中的 state 中派生出一些状态，例如对列表进行过滤并计数。Vuex 允许我们在 store 中定义“getter”（可以认为是 store 的计算属性）。就像计算属性一样，getter 的返回值会根据它的依赖被缓存起来，且只有当它的依赖值发生了改变才会被重新计算。 Getter可以在组件的computed的时候通过get方法进行获取。以及触发Mutation中的方法进行修改。123456789computed: &#123; company: &#123; get() &#123; return this.$store.state.test.company; &#125;, set(value) &#123; this.$store.commit(&quot;CHANGE_COMPANY&quot;, value); &#125; &#125; Mutation更改 Vuex 的 store 中的状态的唯一方法是提交 mutation。它是同步的。 在页面可以直接用commit的方式触发其中的方法。1this.$store.commit(&quot;CHANGE_COMPANY&quot;, value); ActionAction 类似于 mutation，不同在于： Action 提交的是 mutation，而不是直接变更状态。 Action 可以包含任意异步操作。 Action可以通过dispatch来触发。1this.$store.dispatch(&apos;toggleDevice&apos;,this.company) 所有整合主配置index.js1234567891011121314import Vue from &apos;vue&apos;import Vuex from &apos;vuex&apos;import app from &apos;./modules/app&apos;import test from &apos;./modules/test&apos;import getters from &apos;./getters&apos;Vue.use(Vuex)export default new Vuex.Store(&#123; modules: &#123; test &#125;, getters &#125;) store中的某个模块 test.js12345678910111213141516171819202122232425262728293031323334353637383940414243const test = &#123; state: &#123; phone: &#123; name: &apos;xiaomi&apos;, price: 3000 &#125;, company: &apos;xm&apos; &#125;, mutations: &#123; CHANGE_PHONE: (state, device) =&gt; &#123; console.log(&quot;CHANGE_PHONE = device:&quot;+device) if (device == &apos;hw&apos;) &#123; state.phone.price = state.phone.price + 1000 state.phone.name = &apos;huawei&apos; state.phone.company == &apos;hw&apos; &#125; else &#123; state.phone.price = state.phone.price - 1000 state.phone.name = &apos;xiaomi&apos; state.phone.company == &apos;xm&apos; &#125; &#125;, CHANGE_COMPANY: (state, device) =&gt; &#123; console.log(&quot;CHANGE_COMPANY = device:&quot;+device) state.phone.company == device &#125;, &#125;, actions: &#123; toggleDevice(&#123; commit &#125;, device) &#123; console.log(&quot;device:&quot;+device) commit(&apos;CHANGE_PHONE&apos;, device) &#125;, toggleCompany(&#123; commit &#125;, device) &#123; console.log(&quot;device:&quot;+device) commit(&apos;CHANGE_COMPANY&apos;, device) &#125; &#125;&#125;export default test getter.js 1234const getters = &#123; phone: state =&gt; state.test.phone &#125; export default getters 页面模板调用index.vue12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;template&gt; &lt;div&gt; 这是一个layout&#123;&#123;userame&#125;&#125; &lt;input v-model=&quot;company&quot;&gt; &lt;a @click=&quot;handleLogin&quot;&gt;点击我&lt;/a&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import &#123; getTest &#125; from &quot;@/api/login&quot;;export default &#123; name: &quot;Layout&quot;, data() &#123; return &#123; userame: this.$store.state.test.phone.name &#125;; &#125;, computed: &#123; company: &#123; get() &#123; return this.$store.state.test.company; &#125;, set(value) &#123; this.$store.commit(&quot;CHANGE_COMPANY&quot;, value); &#125; &#125; &#125;, methods: &#123; handleLogin() &#123; console.log(&quot;xxxxxxxxxxxxxxxx==&quot;+this.company); console.log(this.$store.getters.phone); // this.$store.commit(&quot;CHANGE_PHONE&quot;, this.$store.state.test.company); this.$store.dispatch(&apos;toggleDevice&apos;,this.company) console.log(this.$store.getters.phone); // getTest(this.userame).then(response =&gt; &#123; // alert(response.data); // this.$store.dispatch(&apos;increment&apos;) // &#125;) &#125; &#125;&#125;;&lt;/script&gt; 其他知识 项目的结构：https://vuex.vuejs.org/zh/guide/structure.html 表单的处理，关于store与表单元素双向绑定的实现：https://vuex.vuejs.org/zh/guide/forms.html 严格模式：https://vuex.vuejs.org/zh/guide/strict.html]]></content>
      <categories>
        <category>Vue</category>
      </categories>
      <tags>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty聊天实现]]></title>
    <url>%2F2018%2F12%2F03%2FNetty%E8%81%8A%E5%A4%A9%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[简介本文主要参考视频教程，然后自己总结一下而已。 启动类主要是配置主线程组和从线程组、绑定端口等基本启动netty服务的操作。 1234567891011121314151617181920212223242526272829303132333435@Componentpublic class WebSocketServer &#123; private EventLoopGroup mainGroup; private EventLoopGroup subGroup; private ServerBootstrap server; private ChannelFuture channelFuture; private static class SingletionWSServer &#123; static final WebSocketServer instance = new WebSocketServer(); &#125; public static WebSocketServer getInstance() &#123; return SingletionWSServer.instance; &#125; public WebSocketServer() &#123; mainGroup = new NioEventLoopGroup(); subGroup = new NioEventLoopGroup(); server = new ServerBootstrap(); server.group(mainGroup,subGroup) .channel(NioServerSocketChannel.class) .childHandler(new WebSocketInitialzer()); &#125; public void start() &#123; this.channelFuture = server.bind(8088); System.err.println(&quot;【Netty Server 启动成功】&quot;); &#125;&#125; 初始化配置类主要配置http相关的处理类、大数据流的支持、对httpMessage进行聚合、心跳检测、websocket相关的处理类、自定义消息处理类。 123456789101112131415161718192021222324252627282930313233343536373839404142public class WebSocketInitialzer extends ChannelInitializer&lt;SocketChannel&gt; &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline pipeline = ch.pipeline(); //======================== http相关============================= //websocket基于http协议，所以需要HttpServerCodec pipeline.addLast(&quot;HttpServerCodec&quot;,new HttpServerCodec()); //对写大数据流的支持 pipeline.addLast(new ChunkedWriteHandler()); //对httpMessage进行聚合，聚合成AggregatedFullHttpRequest和AggregatedFullHttpResponse pipeline.addLast(new HttpObjectAggregator(1024 * 64)); // ====================== 增加心跳支持 start ====================== // 针对客户端，如果在1分钟时没有向服务端发送读写心跳(ALL)，则主动断开 // 如果是读空闲或者写空闲，不处理 pipeline.addLast(new IdleStateHandler(8, 10, 12)); // 自定义的空闲状态检测 pipeline.addLast(new HeartBeatHandler()); // ====================== 增加心跳支持 end ====================== //======================== websocket相关============================= //websocket服务器处理的协议，用于指定给客户端连接访问的路由：&quot;/ws&quot; //本handler会帮你处理一些繁重的复杂的事。会帮你处理握手动作: handshaking //对于websocket来讲，都是以frames进行传输的，不同的数据类型对应的frames也不同。 pipeline.addLast(new WebSocketServerProtocolHandler(&quot;/ws&quot;)); //自定义的handler pipeline.addLast(new ChatHandler()); &#125;&#125; 处理消息的handler主要是对消息传递、channel的操作、心跳处理逻辑都集中在这里处理。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115/** * 处理消息的handler * TextWebSocketFrame：在netty中，是用于websocket专门处理文本的对象，frame是消息的载体。 */public class ChatHandler extends SimpleChannelInboundHandler&lt;TextWebSocketFrame&gt; &#123; //获取到所有的客户端channel。 public static ChannelGroup users = new DefaultChannelGroup(GlobalEventExecutor.INSTANCE); @Override protected void channelRead0(ChannelHandlerContext ctx, TextWebSocketFrame msg) throws Exception &#123; //1.获取客户端发来的消息 String content = msg.text(); Channel currentChannel = ctx.channel(); //2.判断消息类型，根据不同的类型来处理不同的业务 DataContent dataContent = JSONObject.parseObject(content, DataContent.class); Integer action = dataContent.getAction(); if (action == NettyConst.CONNECT)&#123; // 2.1 当websocket，第一次open的时候，初始化channel，把用的channel和userid关联起来 String senderId = dataContent.getChatMsg().getSenderId(); UserChannelRel.put(senderId,currentChannel); &#125;else if (action == NettyConst.CHAT) &#123; // 2.2 聊天类型的消息，把聊天记录保存到数据库中，同时标记消息的签收状态【未签收】 ChatMsg chatMsg = dataContent.getChatMsg(); String msgMsg = chatMsg.getMsg(); String receiverId = chatMsg.getReceiverId(); String senderId = chatMsg.getSenderId(); //保存消息到数据库，并且标记为未签收。 UserService userService = (UserService)SpringUtil.getBean(&quot;userService&quot;); String msgId = userService.saveMsg(chatMsg); chatMsg.setMsgId(msgId); //发送消息 //从全局用户channel关系中获取接收方的channel Channel receiverChannel = UserChannelRel.get(receiverId); if (receiverChannel == null) &#123; //TODO 推送消息 &#125;else &#123; //当receiverChannel不为空是，从channelGroup中查找对应的channel是否存在 Channel findChannel = users.find(receiverChannel.id()); if (findChannel != null) &#123; //用户在线 receiverChannel.writeAndFlush( new TextWebSocketFrame( JSONObject.toJSONString(chatMsg))); &#125;else &#123; //用户离线 &#125; &#125; &#125;else if (action == NettyConst.SIGNED) &#123; // 2.3 签收消息类型，针对具体的消息进行签收，修改数据库中对应的消息签收状态【已签收】 UserService userService = (UserService)SpringUtil.getBean(&quot;userService&quot;); //扩展字段在signed类型的消息中，代表需要去签收的消息id，逗号分隔 String msgIdsStr = dataContent.getExtand(); String[] msgIds = msgIdsStr.split(&quot;,&quot;); List&lt;String&gt; msgIdList = new ArrayList&lt;&gt;(); for (String mid : msgIdList) &#123; if (StringUtils.isNotBlank(mid))&#123; msgIdList.add(mid); &#125; &#125; System.out.println(msgIdList.toString()); if (msgIdList != null &amp;&amp; !msgIdList.isEmpty() &amp;&amp; msgIdList.size() &gt;0) &#123; //批量签收 userService.updateMsgSigned(msgIdList); &#125; &#125;else if (action == NettyConst.KEEPALIVE)&#123; // 2.4 心跳类型的消息 System.out.println(&quot;收到来自channel为[&quot; + currentChannel + &quot;]的心跳包...&quot;); &#125; &#125; /** * 当客户端连接服务端之后（打开连接） * 获取客户端的channel，并且放到ChannelGroup中去进行管理 * @param ctx * @throws Exception */ @Override public void handlerAdded(ChannelHandlerContext ctx) throws Exception &#123; users.add(ctx.channel()); &#125; @Override public void handlerRemoved(ChannelHandlerContext ctx) throws Exception &#123; //当触发handler销毁时，这个会自动的移除的。 users.remove(ctx.channel()); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); //发生异常之后关闭连接，随后从ChannelGroup中移除 ctx.channel().close(); users.remove(ctx.channel()); &#125;&#125; 心跳处理handler12345678910111213141516171819202122232425262728public class HeartBeatHandler extends ChannelInboundHandlerAdapter &#123; @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123; // 判断evt是否是IdleStateEvent（用于触发用户事件，包含 读空闲/写空闲/读写空闲 ） if (evt instanceof IdleStateEvent) &#123; IdleStateEvent event = (IdleStateEvent)evt; // 强制类型转换 if (event.state() == IdleState.READER_IDLE) &#123; System.out.println(&quot;进入读空闲...&quot;); &#125; else if (event.state() == IdleState.WRITER_IDLE) &#123; System.out.println(&quot;进入写空闲...&quot;); &#125; else if (event.state() == IdleState.ALL_IDLE) &#123; System.out.println(&quot;channel关闭前，users的数量为：&quot; + ChatHandler.users.size()); Channel channel = ctx.channel(); // 关闭无用的channel，以防资源浪费 channel.close(); System.out.println(&quot;channel关闭后，users的数量为：&quot; + ChatHandler.users.size()); &#125; &#125; &#125;&#125; 聊天实体类DataContent1234567891011@Datapublic class DataContent implements Serializable&#123; private static final long serialVersionUID = 1L; private Integer action; //动作类型 private ChatMsg chatMsg; //用户的聊天内容entity private String extand; //扩展字段&#125; 页面中的调用websocket服务12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot; /&gt; &lt;title&gt;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;div&gt;发送消息&lt;/div&gt; &lt;input type=&quot;text&quot; id=&quot;msgContent&quot; /&gt; &lt;input type=&quot;button&quot; value=&quot;点我发送&quot; onclick=&quot;CHAT.chat()&quot; /&gt; &lt;div&gt;接收消息：&lt;/div&gt; &lt;div id=&quot;receiveMsg&quot; style=&quot;background: gray;&quot;&gt;&lt;/div&gt; &lt;script type=&quot;application/javascript&quot;&gt; window.CHAT = &#123; socket: null, init: function() &#123; if (window.WebSocket)&#123; CHAT.socket = new WebSocket(&quot;ws://192.168.11.138:8088/ws&quot;); CHAT.socket.onopen = function() &#123; console.log(&quot;onopen连接成功。。。&quot;); &#125;, CHAT.socket.onclose = function() &#123; console.log(&quot;onclose连接关闭。。。&quot;); &#125;, CHAT.socket.onerror = function() &#123; console.log(&quot;onerror发生异常。。。&quot;); &#125;, CHAT.socket.onmessage = function(e) &#123; console.log(&quot;onmessage接收到消息:&quot;+e.data); var receiveMsg = document.getElementById(&quot;receiveMsg&quot;); var html = receiveMsg.innerHTML; receiveMsg.innerHTML = html+&quot;&lt;br&gt;&quot; + e.data; &#125; &#125;else&#123; alert(&quot;浏览器不支持websocket协议.....&quot;); &#125; &#125;, chat: function() &#123; var msg = document.getElementById(&quot;msgContent&quot;); CHAT.socket.send(msg.value); &#125; &#125; CHAT.init(); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 总结路漫漫其修远兮，吾将上下而求索。]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue全家桶整合]]></title>
    <url>%2F2018%2F12%2F01%2FVue%E5%85%A8%E5%AE%B6%E6%A1%B6%E6%95%B4%E5%90%88%2F</url>
    <content type="text"><![CDATA[Vue-routerVue的路由，先献上文档（https://router.vuejs.org/zh-cn/） 路由在Vue全家桶里面定位是什么呢，创建单页应用！简单！我们知道Vuejs是一系列的组件组成应用，既然是组件那么就需要组合起来，将组件(components)映射到路由(routes)，然后告诉 vue-router 在哪里渲染它们！ 参考配置： 1234567891011121314151617181920212223242526import Vue from &apos;vue&apos;import Router from &apos;vue-router&apos;Vue.use(Router)import Layout from &apos;@/views/layout/Layout&apos;export const constantRouterMap = [ &#123; path: &apos;/&apos;, component: Layout, children: [ &#123; path: &apos;/&apos;, component: () =&gt; import(&apos;@/views/login/index&apos;) &#125; ] &#125;]export default new Router(&#123; // mode: &apos;history&apos;, // require service support scrollBehavior: () =&gt; (&#123; y: 0 &#125;), routes: constantRouterMap &#125;) Vuex献上文档（https://vuex.vuejs.org/zh-cn/） Vuex 是一个专为 Vue.js 应用程序开发的状态管理模式。什么是状态管理？可以简单理解为管理数据流，多页面共享一个data库（全局）。 参考配置： 导入vuex的配置index.js 12345678910111213141516import Vue from &apos;vue&apos;import Vuex from &apos;vuex&apos;import app from &apos;./modules/app&apos;import test from &apos;./modules/test&apos;import getters from &apos;./getters&apos;Vue.use(Vuex)export default new Vuex.Store(&#123; modules: &#123; app, test &#125;, getters &#125;) 配置相关参数test.js 1234567const test = &#123; state: &#123; mytest: &apos;12312312313&apos; &#125;&#125;export default test 在组件调用 12345678910111213141516171819202122232425262728293031&lt;template&gt; &lt;div&gt; 这是一个layout&#123;&#123;userame&#125;&#125; &lt;a @click=&quot;handleLogin&quot;&gt;点击我&lt;/a&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import &#123; getTest &#125; from &apos;@/api/login&apos;export default &#123; name: &apos;Layout&apos;, data() &#123; return &#123; userame: this.$store.state.test.mytest &#125; &#125;, computed: &#123; count () &#123; return this.$store.state.test.mytest &#125; &#125;, methods: &#123; handleLogin() &#123; getTest(this.userame).then(response =&gt; &#123; alert(response.data); &#125;) &#125; &#125;&#125;&lt;/script&gt; axios封装的ajax,可以根据自己的项目情况再进行封装，然后action中调用。具体可以参考https://github.com/mzabriskie/axios 参考配置： 封装 request.js请求工具 123456789101112131415161718192021222324252627import axios from &apos;axios&apos;// import store from &apos;@/store&apos;// 创建axios实例const service = axios.create(&#123; baseURL: &apos;&apos;, timeout: 15000 // 请求超时时间&#125;)service.interceptors.response.use( function (response) &#123; //请求正常则返回 return Promise.resolve(response) &#125;, function (error) &#123; // 请求错误则向store commit这个状态变化 // const httpError = &#123; // hasError: true, // status: error.response.status, // statusText: error.response.statusText // &#125; // store.commit(&apos;ON_HTTP_ERROR&apos;, httpError) return Promise.reject(error) &#125;)export default service 自定义的api请求login.js 12345678910import request from &apos;@/utils/request&apos;export function getTest(params) &#123; return request(&#123; url: &apos;/u/register&apos;, method: &apos;get&apos;, params &#125;)&#125; 在组件中调用 1234567891011121314151617181920212223242526272829303132 &lt;template&gt; &lt;div&gt; 这是一个layout&#123;&#123;userame&#125;&#125; &lt;a @click=&quot;handleLogin&quot;&gt;点击我&lt;/a&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import &#123; getTest &#125; from &apos;@/api/login&apos;export default &#123; name: &apos;Layout&apos;, data() &#123; return &#123; userame: this.$store.state.test.mytest &#125; &#125;, computed: &#123; count () &#123; return this.$store.state.test.mytest &#125; &#125;, methods: &#123; handleLogin() &#123; getTest(this.userame).then(response =&gt; &#123; alert(response.data); &#125;) &#125; &#125;&#125;&lt;/script&gt; 总结参考GitHub 整合源码]]></content>
      <categories>
        <category>Vue</category>
      </categories>
      <tags>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FastFDS安装教程]]></title>
    <url>%2F2018%2F11%2F23%2FfastFDS%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[简介FastDFS是一个开源的轻量级分布式文件系统,由跟踪服务器(tracker server)、存储服务器(storage server)和客户端(client)三个部分组成,主要解决了海量数据存储问题,特别适合以中小文件(建议范围:4KB &lt; file_size &lt;500MB)为载体的在线服务。 本文基于阿里云centos7.2 准备工作 1.余大的GitHub: https://github.com/happyfish100 中的fastdfs、libfastcommon、fastdfs-nginx-module 这三个需要下载。 2.下载Nginx。链接地址 http://nginx.org/en/download.html 开始安装FastFDS安装 1、安装工具 12345yum -y install unzip zipyum -y install gcc-c++yum -y install pcre pcre-devel yum -y install zlib zlib-devel yum -y install openssl openssl-devel 2、上传fastfds、libfastcommon、fastdfs-nginx-module到/usr/local/ 目录下并解压 1234unzip libfastcommon-master.zipunzip fastdfs-nginx-module-master.ziptar -zxvf fastdfs-5.11.tar.gztar -zxvf nginx-1.14.1.tar.gz 3、安装libfastcommon进入libfastcommon目录，运行 12./make./make install 至此libfastcommon就已经安装成功了,但注意一下上图中红色框标注的内容,libfastcommon.so 默认安装到了/usr/lib64/libfastcommon.so,但是FastDFS主程序设置的lib目录是/usr/local/lib,所以此处需要重新设置软链接(类似于Windows的快捷方式):1234ln -s /usr/lib64/libfastcommon.so /usr/local/lib/libfastcommon.so ln -s /usr/lib64/libfastcommon.so /usr/lib/libfastcommon.so ln -s /usr/lib64/libfdfsclient.so /usr/local/lib/libfdfsclient.so ln -s /usr/lib64/libfdfsclient.so /usr/lib/libfdfsclient.so 4、安装fastfds进入fastfds的目录12./make.sh ./make.sh install 安装完成，修改配置文件，到/etc/fdfs中运行123cp client.conf.sample client.conf cp storage.conf.sample storage.conf cp tracker.conf.sample tracker.conf 5、配置Tracker创建Tracker服务器的文件路径1mkdir /opt/fastdfs_tracker 编辑上一步准备好的/etc/fdfs目录下的tracker.conf配置如下：1234disabled=false#启用配置文件(默认启用) port=22122#设置tracker的端口号,通常采用22122这个默认端口 base_path=/opt/fastdfs_tracker#设置tracker的数据文件和日志目录 http.server_port=6666#设置http端口号,默认为8080 接着为启动脚本创建软引用,因为fdfs_trackerd等命令在/usr/local/bin中并没有。123ln -s /usr/bin/fdfs_trackerd /usr/local/bin ln -s /usr/bin/stop.sh /usr/local/bin ln -s /usr/bin/restart.sh /usr/local/bin 最后启动Tracker服务器:1service fdfs_trackerd start 查看启动状况1netstat -unltp|grep fdfs 如下图表示成功了 6、配置Storage创建Storage服务器的文件目录12mkdir /opt/fastdfs_storage mkdir /opt/fastdfs_storage_data 接下来修改/etc/fdfs目录下的storage.conf配置文件,打开文件后依次做以下修改:12345678disabled=false#启用配置文件(默认启用) group_name=group1#组名,根据实际情况修改 port=23000 #设置storage的端口号,默认是23000,同一个组的storage端口号必须一致 base_path=/opt/fastdfs_storage#设置storage数据文件和日志目录 store_path_count=1 #存储路径个数,需要和store_path个数匹配 store_path0=/opt/fastdfs_storage_data #实际文件存储路径 tracker_server=192.168.112.16:22122 #tracker 服务器的 IP地址和端口号,如果是单机搭建,IP不要写127.0.0.1,否则启动不成功(此处的ip是我的CentOS虚拟机ip) http.server_port=8888#设置 http 端口号 配置完成后同样要为Storage服务器的启动脚本设置软引用:1ln -s /usr/bin/fdfs_storaged /usr/local/bin 启动Storage服务了: 1service fdfs_storaged start 验证是否成功：可以到/opt/fastdfs_storage/data目录下生成好的pid文件和dat文件,那么再看一下实际文件存储路径下是否有创建好的多级目录呢: 如下图就是成功了。 查看端口是否正常。1netstat -unltp|grep fdfs 7、测试上传测试时需要设置客户端的配置文件,编辑/etc/fdfs目录下的client.conf 文件,打开文件后依次做以下修改:123base_path=/opt/fastdfs_tracker#tracker服务器文件路径 tracker_server=192.168.111.11:22122#tracker服务器IP地址和端口号 http.tracker_server_port=6666# tracker 服务器的 http 端口号,必须和tracker的设置对应起来 上传一张照片上去：例如：1/usr/bin/fdfs_upload_file /etc/fdfs/client.conf /opt/54ffac56000169c001840181.jpg 成功如下图 FastDFS与nginx进行集成 1、加入模块加入模块命令：(对准你的fastdfs-nginx-module安装包）。 123./configure --add-module=/usr/local/fast/fastdfs-nginx-module/src/make &amp;&amp; make install 复制fastdfs-ngin-module中的配置文件，到/etc/fdfs目录中1cp /usr/local/fast/fastdfs-nginx-module/src/mod_fastdfs.conf /etc/fdfs/ 修改mod_fastdfs.conf12345#修改内容：比如连接超时时间、跟踪器路径配置、url的group配置、connect_timeout=10tracker_server=192.168.1.172:22122url_have_group_name = truestore_path0=/opt/fastdfs_storage_data #这个要跟storage的相同。 复制FastDFS里的2个文件，到/etc/fdfs目录中12cd /usr/local/fast/FastDFS/conf/cp http.conf mime.types /etc/fdfs/ 创建一个软连接，在/fastdfs/storage文件存储目录下创建软连接，将其链接到实际存放数据的目录。1ln -s /fastdfs/storage/data/ /fastdfs/storage/data/M00 修改配置nginx.conf 修改内容为：1234567listen 8888;server_name localhost;location ~/group([0-9])/M00 &#123;root /fastdfs/storage/data;ngx_fastdfs_module;&#125; 启动Nginx1/usr/local/nginx/sbin/nginx 现在我们使用这个ID用浏览器访问地址：http://120.79.226.4:8888/group1/M00/00/00/rBJeZVv4AbqAJlGpAACoAPN3PCk295.jpg 特别提醒：阿里云的端口需要到安全组配置里配置才能访问的。 参考文章 1、https://www.cnblogs.com/tc520/p/6822412.html 2、https://www.aliyun.com/jiaocheng/28474.html?spm=5176.100033.2.7.279346ddqJL0aa]]></content>
      <categories>
        <category>软件安装</category>
      </categories>
      <tags>
        <tag>FastFDS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nettty入门实例]]></title>
    <url>%2F2018%2F11%2F13%2FNettty%E5%85%A5%E9%97%A8%E5%AE%9E%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[步骤 构建一对主从线程组 定义服务器启动类 为服务设置Channel 设置处理从线程池的Handler初始化器 监听启动和关闭服务器 代码入口类：HelloServer1234567891011121314151617181920212223242526272829303132333435import io.netty.bootstrap.ServerBootstrap;import io.netty.channel.ChannelFuture;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.nio.NioServerSocketChannel;public class HelloServer &#123; public static void main(String[] args) throws InterruptedException &#123; //定义一对线程组 //主线程组，用于接受客户端的连接，但是不做任何处理，跟老板一样，不做事 EventLoopGroup bossGroup = new NioEventLoopGroup(); //从线程组，老板线程组会把任务丢给他，让手下线程组做任务 EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; //netty服务器创建，ServerBootstrap是一个启动类 ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.group(bossGroup,workerGroup)//设置主从线程组 .channel(NioServerSocketChannel.class)//设置nio的双向通道 .childHandler(new HelloServerInitlializer());//子处理器，用于处理workerGroup //启动server，并且设置8888为启动的端口号，同时启动方式为同步 ChannelFuture channelFuture = serverBootstrap.bind(8888).sync(); //监听关闭的channel，设置位同步方式。 channelFuture.channel().closeFuture().sync(); &#125;finally &#123; bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125;&#125; 初始化channel器图解：channel的初始化器的作用。 代码12345678910111213141516171819202122232425import io.netty.channel.ChannelInitializer;import io.netty.channel.ChannelPipeline;import io.netty.channel.socket.SocketChannel;import io.netty.handler.codec.http.HttpServerCodec;/** * 初始化器，channel注册后，会执行里面的对应的初始化方法。 */public class HelloServerInitlializer extends ChannelInitializer&lt;SocketChannel&gt; &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; //通过socketChannel获得对应的管道 ChannelPipeline pipeline = socketChannel.pipeline(); //通过管道，添加handler // HttpServerCodec 当请求到服务端，我们需要做解码，响应到客户端需要做编码 pipeline.addLast("HttpServerCodec",new HttpServerCodec()); //添加的自定义handler pipeline.addLast("myHandler",new MyHandler()); &#125;&#125; 自定义Handler123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.Channel;import io.netty.channel.ChannelHandlerContext;import io.netty.channel.SimpleChannelInboundHandler;import io.netty.handler.codec.http.*;import io.netty.util.CharsetUtil;/** * 自定义的handler * SimpleChannelInboundHandler: 相当于队列入栈。 */public class MyHandler extends SimpleChannelInboundHandler&lt;HttpObject&gt; &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, HttpObject msg) throws Exception &#123; //获取channel Channel channel = ctx.channel(); if (msg instanceof HttpRequest) &#123; //显示客户端远程地址 System.out.println(channel.remoteAddress()); //定义发送的数据消息 ByteBuf content = Unpooled.copiedBuffer("hello sb!", CharsetUtil.UTF_8); //构建一个http response FullHttpResponse response = new DefaultFullHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.OK, content); //设置类型和长度 response.headers().set(HttpHeaderNames.CONTENT_TYPE, "text/plain"); response.headers().set(HttpHeaderNames.CONTENT_LENGTH, content.readableBytes()); ctx.writeAndFlush(response); &#125; &#125; @Override public void channelRegistered(ChannelHandlerContext ctx) throws Exception &#123; super.channelRegistered(ctx); System.out.println("channel 注册。。。"); &#125; @Override public void channelUnregistered(ChannelHandlerContext ctx) throws Exception &#123; super.channelUnregistered(ctx); System.out.println("channel 移除。。。"); &#125; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; super.channelActive(ctx); System.out.println("channel 激活。。。"); &#125; @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; super.channelInactive(ctx); System.out.println("channel 不活跃。。。"); &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; super.channelReadComplete(ctx); System.out.println("channel 读取完成。。。"); &#125; @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123; super.userEventTriggered(ctx, evt); System.out.println("channel 用户事件触发。。。"); &#125; @Override public void channelWritabilityChanged(ChannelHandlerContext ctx) throws Exception &#123; super.channelWritabilityChanged(ctx); System.out.println("channel 可写可更改。。。"); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; super.exceptionCaught(ctx, cause); System.out.println("channel 捕获异常了。。。"); &#125; @Override public void handlerAdded(ChannelHandlerContext ctx) throws Exception &#123; super.handlerAdded(ctx); System.out.println("channel handler添加。。。"); &#125; @Override public void handlerRemoved(ChannelHandlerContext ctx) throws Exception &#123; super.handlerRemoved(ctx); System.out.println("channel handler移除。。。"); &#125;&#125;]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty基础知识]]></title>
    <url>%2F2018%2F11%2F12%2FNetty%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[阻塞与非阻塞线程访问资源，该资源是否准备就绪的一种处理方式。 阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程 线程A ——–&gt; 处理中线程B ——–&gt; 处理中 同步与异步同步和异步是指访问数据的一种机制。同步就是在发出一个请求时，在没有得到结果之前，该请求就不返回。但是一旦调用返回，就得到返回值了。异步则是相反，请求在发出之后，这个请求就直接返回了，所以没有返回结果。换句话说，当一个异步过程调用发出后，客户端不会立刻得到结果。而是在请求发出后，服务器通过状态、通知来通知请求者（客户端），或通过回调函数处理这个请求。 BIO同步阻塞的IO,Block IO 最广泛的模型是阻塞I/O模型，默认情况下，所有套接口都是阻塞的。 进程调用recvfrom系统调用，整个过程是阻塞的，直到数据复制到进程缓冲区时才返回（当然，系统调用被中断也会返回）。 NIO同步非阻塞IO, New IO (Non-Block IO) 当我们把一个套接口设置为非阻塞时，就是在告诉内核，当请求的I/O操作无法完成时，不要将进程睡眠，而是返回一个错误。当数据没有准备好时，内核立即返回EWOULDBLOCK错误，第四次调用系统调用时，数据已经存在，这时将数据复制到进程缓冲区中。这其中有一个操作时轮询（polling）。 AIO异步非阻塞IO 进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。 这个模型工作机制是：告诉内核启动某个操作，并让内核在整个操作(包括第二阶段，即将数据从内核拷贝到进程缓冲区中)完成后通知我们。 Reactor线程模型主从线程模型：一组线程池接受请求，一组线程池处理io 可参考这篇文章 通俗地讲： BIO:去上厕所，坑全满，此时你一直光等着，主动观察哪个坑位好了，只要有坑位释放了，你就立马去占坑。 NIO: 厕所坑全满，此时你跑过去抽烟或者做别的事，然后时不时再主动的去厕所看有没有坑释放，如果有坑了自己去占。 AIO:你在厕所外抽烟玩手机，等有人好了之后来通知你去占坑。 常见面试 BIO,NIO,AIO的区别是什么？可参考这篇文章 参考链接 https://blog.csdn.net/u013068377/article/details/70312551 https://blog.csdn.net/king866/article/details/54427447]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[asyncSupported]]></title>
    <url>%2F2018%2F11%2F07%2FasyncSupported%2F</url>
    <content type="text"><![CDATA[简介@WebServlet@WebServlet 用于将一个类声明为 Servlet，该注解将会在部署时被容器处理，容器将根据具体的属性配置将相应的类部署为 Servlet。该注解具有下表给出的一些常用属性（以下所有属性均为可选属性，但是 vlaue 或者 urlPatterns 通常是必需的，且二者不能共存，如果同时指定，通常是忽略 value 的取值） 属性名 类型 描述 name String 指定 Servlet 的 name 属性，等价于 。如果没有显式指定，则该 Servlet 的取值即为类的全限定名。 value String[] 该属性等价于 urlPatterns 属性。两个属性不能同时使用。 urlPatterns String[] 指定一组 Servlet 的 URL 匹配模式。等价于 标签。 loadOnStartup int 指定 Servlet 的加载顺序，等价于 标签。 initParams WebInitParam[] 指定一组 Servlet 初始化参数，等价于 标签。 asyncSupported boolean 声明 Servlet 是否支持异步操作模式，等价于 标签。 description String 该 Servlet 的描述信息，等价于 标签。 displayName String 该 Servlet 的显示名，通常配合工具使用，等价于 标签。 实例123456789101112131415161718192021222324252627282930313233343536@WebServlet(value="/async",asyncSupported=true)public class HelloAsyncServlet extends HttpServlet &#123; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; //1、支持异步处理asyncSupported=true //2、开启异步模式 System.out.println("主线程开始。。。"+Thread.currentThread()+"==&gt;"+System.currentTimeMillis()); AsyncContext startAsync = req.startAsync(); //3、业务逻辑进行异步处理;开始异步处理 startAsync.start(new Runnable() &#123; @Override public void run() &#123; try &#123; System.out.println("副线程开始。。。"+Thread.currentThread()+"==&gt;"+System.currentTimeMillis()); sayHello(); startAsync.complete(); //获取到异步上下文 AsyncContext asyncContext = req.getAsyncContext(); //4、获取响应 ServletResponse response = asyncContext.getResponse(); response.getWriter().write("hello async..."); System.out.println("副线程结束。。。"+Thread.currentThread()+"==&gt;"+System.currentTimeMillis()); &#125; catch (Exception e) &#123; &#125; &#125; &#125;); System.out.println("主线程结束。。。"+Thread.currentThread()+"==&gt;"+System.currentTimeMillis()); &#125; public void sayHello() throws Exception&#123; System.out.println(Thread.currentThread()+" processing..."); Thread.sleep(3000); &#125;&#125;]]></content>
      <categories>
        <category>Spring源码</category>
      </categories>
      <tags>
        <tag>Spring源码</tag>
        <tag>Servlet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ServletContainerInitializer]]></title>
    <url>%2F2018%2F11%2F07%2FServletContainerInitializer%2F</url>
    <content type="text"><![CDATA[简介 在web容器启动时为提供给第三方组件机会做一些初始化的工作，例如注册》servlet或者filtes等，servlet规范中通过ServletContainerInitializer实现此功能。每个框架要使用ServletContainerInitializer就必须在对应的jar包的META-INF/services 目录创建一个名为javax.servlet.ServletContainerInitializer的文件，文件内容指定具体的ServletContainerInitializer实现类。 实现步骤1、Servlet容器启动会扫描，当前应用里面每一个jar包的 ServletContainerInitializer的实现2、提供ServletContainerInitializer的实现类； 必须绑定在，META-INF/services/javax.servlet.ServletContainerInitializer 文件的内容就是ServletContainerInitializer实现类的全类名； 3、代码：MyServletContainerInitializer.java 123456789101112131415161718192021222324252627282930313233343536373839404142//容器启动的时候会将@HandlesTypes指定的这个类型下面的子类（实现类，子接口等）传递过来；//传入感兴趣的类型；@HandlesTypes(value=&#123;HelloService.class&#125;)public class MyServletContainerInitializer implements ServletContainerInitializer &#123; /** * 应用启动的时候，会运行onStartup方法； * * Set&lt;Class&lt;?&gt;&gt; arg0：感兴趣的类型的所有子类型； * ServletContext arg1:代表当前Web应用的ServletContext；一个Web应用一个ServletContext； * * 1）、使用ServletContext注册Web组件（Servlet、Filter、Listener） * 2）、使用编码的方式，在项目启动的时候给ServletContext里面添加组件； * 必须在项目启动的时候来添加； * 1）、ServletContainerInitializer得到的ServletContext； * 2）、ServletContextListener得到的ServletContext； */ @Override public void onStartup(Set&lt;Class&lt;?&gt;&gt; arg0, ServletContext sc) throws ServletException &#123; // TODO Auto-generated method stub System.out.println("感兴趣的类型："); for (Class&lt;?&gt; claz : arg0) &#123; System.out.println(claz); &#125; //注册组件 ServletRegistration ServletRegistration.Dynamic servlet = sc.addServlet("userServlet", new UserServlet()); //配置servlet的映射信息 servlet.addMapping("/user"); //注册Listener sc.addListener(UserListener.class); //注册Filter FilterRegistration FilterRegistration.Dynamic filter = sc.addFilter("userFilter", UserFilter.class); //配置Filter的映射信息 filter.addMappingForUrlPatterns(EnumSet.of(DispatcherType.REQUEST), true, "/*"); &#125;&#125; 总结容器在启动应用的时候，会扫描当前应用每一个jar包里面META-INF/services/javax.servlet.ServletContainerInitializer指定的实现类，启动并运行这个实现类的方法；传入感兴趣的类型。]]></content>
      <categories>
        <category>Spring源码</category>
      </categories>
      <tags>
        <tag>Spring源码</tag>
        <tag>Servlet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ApplicationListener]]></title>
    <url>%2F2018%2F11%2F07%2FApplicationListener%2F</url>
    <content type="text"><![CDATA[简介ApplicationListener：监听容器中发布的事件。 实例MyApplicationListener.java1234567891011@Componentpublic class MyApplicationListener implements ApplicationListener&lt;ApplicationEvent&gt; &#123; //当容器中发布此事件以后，方法触发 @Override public void onApplicationEvent(ApplicationEvent event) &#123; // TODO Auto-generated method stub System.out.println("收到事件："+event); &#125;&#125; 配置类12345678910@ComponentScan("com.atguigu.ext")@Configurationpublic class ExtConfig &#123; @Bean public Blue blue()&#123; return new Blue(); &#125;&#125; 测试类1234567891011@Testpublic void test01()&#123; AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(ExtConfig.class); //发布事件； applicationContext.publishEvent(new ApplicationEvent(new String("我发布的时间")) &#123; &#125;); applicationContext.close();&#125; 原理监听 ApplicationEvent 及其下面的子事件： 步骤： 1）、写一个监听器（ApplicationListener实现类）来监听某个事件（ApplicationEvent及其子类）@EventListener;原理：使用EventListenerMethodProcessor处理器来解析方法上的@EventListener； 2）、把监听器加入到容器； 3）、只要容器中有相关事件的发布，我们就能监听到这个事件；ContextRefreshedEvent：容器刷新完成（所有bean都完全创建）会发布这个事件；ContextClosedEvent：关闭容器会发布这个事件； 4）、发布一个事件：applicationContext.publishEvent()； 发布事件的原理： ContextRefreshedEvent、IOCTest_Ext$1[source=我发布的时间]、ContextClosedEvent； 1）、ContextRefreshedEvent事件：a、容器创建对象：refresh()；b、finishRefresh();容器刷新完成会发布ContextRefreshedEvent事件 2）、自己发布事件； 3）、容器关闭会发布ContextClosedEvent； 【事件发布流程】： publishEvent(new ContextRefreshedEvent(this)); 1）、获取事件的多播器（派发器）：getApplicationEventMulticaster() 2）、multicastEvent派发事件； 3）、获取到所有的ApplicationListener；for (final ApplicationListener&lt;?&gt; listener : getApplicationListeners(event, type)) { &emsp;&emsp;a）、如果有Executor，可以支持使用Executor进行异步派发；Executor executor = getTaskExecutor(); &emsp;&emsp;b）、否则，同步的方式直接执行listener方法；invokeListener(listener, event); 拿到listener回调onApplicationEvent方法； 其他知识SmartInitializingSingleton 接口 看spring jms的代码时，发现SmartInitializingSingleton 这个接口也比较有意思。 就是当所有的singleton的bean都初始化完了之后才会回调这个接口。不过要注意是 4.1 之后才出现的接口。 123456789101112131415public interface SmartInitializingSingleton &#123; /** * Invoked right at the end of the singleton pre-instantiation phase, * with a guarantee that all regular singleton beans have been created * already. &#123;@link ListableBeanFactory#getBeansOfType&#125; calls within * this method won't trigger accidental side effects during bootstrap. * &lt;p&gt;&lt;b&gt;NOTE:&lt;/b&gt; This callback won't be triggered for singleton beans * lazily initialized on demand after &#123;@link BeanFactory&#125; bootstrap, * and not for any other bean scope either. Carefully use it for beans * with the intended bootstrap semantics only. */ void afterSingletonsInstantiated(); &#125;]]></content>
      <categories>
        <category>Spring源码</category>
      </categories>
      <tags>
        <tag>Spring源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BeanPostProcessor和BeanFactoryPostProcessor]]></title>
    <url>%2F2018%2F11%2F05%2FBeanPostProcessor%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[BeanPostProcessor简介BeanPostProcessor是Spring IOC容器给我们提供的一个扩展接口。接口声明如下：123456public interface BeanPostProcessor &#123; //bean初始化方法调用前被调用 Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException; //bean初始化方法调用后被调用 Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException;&#125; 运行顺序 ===Spring IOC容器实例化Bean=== ===调用BeanPostProcessor的postProcessBeforeInitialization方法=== ===调用bean实例的初始化方法=== ===调用BeanPostProcessor的postProcessAfterInitialization方法=== BeanPostProcessor实例12345678910111213141516171819202122/** * 后置处理器：初始化前后进行处理工作 * 将后置处理器加入到容器中 */@Componentpublic class MyBeanPostProcessor implements BeanPostProcessor &#123; @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; // TODO Auto-generated method stub System.out.println(&quot;postProcessBeforeInitialization...&quot;+beanName+&quot;=&gt;&quot;+bean); return bean; &#125; @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; // TODO Auto-generated method stub System.out.println(&quot;postProcessAfterInitialization...&quot;+beanName+&quot;=&gt;&quot;+bean); return bean; &#125;&#125; BeanFactoryPostProcessor简介bean工厂的bean属性处理容器，说通俗一些就是可以管理我们的bean工厂内所有的beandefinition（未实例化）数据，可以随心所欲的修改属性。 BeanFactoryPostProcessor实例1234567891011121314@Componentpublic class MyBeanFactoryPostProcessor implements BeanFactoryPostProcessor &#123; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; System.out.println("MyBeanFactoryPostProcessor...postProcessBeanFactory..."); int count = beanFactory.getBeanDefinitionCount(); String[] names = beanFactory.getBeanDefinitionNames(); System.out.println("当前BeanFactory中有"+count+" 个Bean"); System.out.println(Arrays.asList(names)); &#125;&#125; 区别： 注册BeanFactoryPostProcessor的实例，需要重载 void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException; 通过beanFactory可以获取bean的示例或定义等。同时可以修改bean的属性，这是和BeanPostProcessor最大的区别。]]></content>
      <categories>
        <category>Spring源码</category>
      </categories>
      <tags>
        <tag>Spring源码</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringAOP]]></title>
    <url>%2F2018%2F10%2F31%2FSpringAOP%2F</url>
    <content type="text"><![CDATA[AOP定义AOP指在程序运行期间动态的将某段代码切入到指定方法指定位置运行的编程方式。 AOP流程 导入aop模块：Spring AOP(spring-aspects) 定义一个业务逻辑类（MathCalculator）：在业务逻辑运行的时候将日志进行打印（方法之前、方法运行结束、方法出现异常、xxxx） 定义一个日志切面类（LogAspects）：切面类里面的方法需要动态感知MathCalculator.div 运行到哪里然后执行： 通知方法： 前置通知(@Before)：logStart：在目标方法（div）运行之前运行 后置通知(@After)：logEnd:在目标方法（div）运行结束之后运行（无论方法正常结束还是异常结束） 返回通知(@AfterReturning)：logReturn：在目标方法（div）正常返回之后运行 异常通知（@AfterThrowing）：logException：在目标方法（div）出现异常以后运行。 环绕通知（@Around）：动态代理，手动推进目标方法运行（joinPoint.procced()） 给切面类的目标方法标注何时何地运行（通知注解） 将切面类和业务逻辑类（目标方法所在类）都加入到容器中； 6.必须告诉spring哪个类是切面类（给切面类加一个注解@Aspect） 7、给配置类中加 @EnableAspectJAutoProxy 【开启基于注解的aop模式】在Spring中很多的@EnableXXX; AOP实例1)、将业务逻辑组件和切面类都加入到容器中；告诉spring哪个是切面类（@Aspect） 2)、在切面类上的每一个通知方法上标注通知注解，告诉spring何时何地运行（切入点表达式） 3)、开启基于注解的aop模式：@EnableAspectJAutoProxy MainConfigOfAOP.java12345678910111213141516@EnableAspectJAutoProxy@Configurationpublic class MainConfigOfAOP &#123; //业务逻辑类加入容器中 @Bean public MathCalculator calculator()&#123; return new MathCalculator(); &#125; //切面类加入到容器中 @Bean public LogAspects logAspects()&#123; return new LogAspects(); &#125;&#125; MathCalculator.java 12345678public class MathCalculator &#123; public int div(int i,int j)&#123; System.out.println("MathCalculator...div..."); return i/j; &#125;&#125; LogAspects.java123456789101112131415161718192021222324252627282930313233343536373839/** * 切面类 * * @Aspect： 告诉Spring当前类是一个切面类 * */@Aspectpublic class LogAspects &#123; //抽取公共的切入点表达式 //1、本类引用 //2、其他的切面引用 @Pointcut("execution(public int com.atguigu.aop.MathCalculator.*(..))") public void pointCut()&#123;&#125;; //@Before在目标方法之前切入；切入点表达式（指定在哪个方法切入） @Before("pointCut()") public void logStart(JoinPoint joinPoint)&#123; Object[] args = joinPoint.getArgs(); System.out.println(""+joinPoint.getSignature().getName()+"运行。。。@Before:参数列表是：&#123;"+Arrays.asList(args)+"&#125;"); &#125; @After("com.atguigu.aop.LogAspects.pointCut()") public void logEnd(JoinPoint joinPoint)&#123; System.out.println(""+joinPoint.getSignature().getName()+"结束。。。@After"); &#125; //JoinPoint一定要出现在参数表的第一位 @AfterReturning(value="pointCut()",returning="result") public void logReturn(JoinPoint joinPoint,Object result)&#123; System.out.println(""+joinPoint.getSignature().getName()+"正常返回。。。@AfterReturning:运行结果：&#123;"+result+"&#125;"); &#125; @AfterThrowing(value="pointCut()",throwing="exception") public void logException(JoinPoint joinPoint,Exception exception)&#123; System.out.println(""+joinPoint.getSignature().getName()+"异常。。。异常信息：&#123;"+exception+"&#125;"); &#125;&#125;]]></content>
      <categories>
        <category>Spring源码</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring自动装配]]></title>
    <url>%2F2018%2F10%2F14%2FSpring%E8%87%AA%E5%8A%A8%E8%A3%85%E9%85%8D%2F</url>
    <content type="text"><![CDATA[@AutoWired，自动注入：Spring利用依赖注入（DI),完成对IOC容器中各个组件的依赖关系赋值。 a、默认优先按照【类型】去容器中找对应的组件：application.getBean(CarDao.class); b、如果找到多个相同类型的组件，再将属性的名称作为组件的id去容器中查找applicationContext.getBean(“carDao”) c、@Qualifier(“carDao”),使用Qualifier指定需要装配的组件的id，而不是使用属性名 d、自动装配默认一定要将属性赋值好，没有就会报错；可以使用@Autowired(required = false) e、@Primary:让spring进行自动装配的时候，默认使用首选的bean；还可以继续使用@Qualifier进行明确指定（优先级最高）。 @AutoWired：可以标记在构造器、参数、方法、属性上：都是从容器中获取参数组件的值 a、标注在【构造器】上：如果组件只有一个有参构造器，这个有参构造器的@AutoWired可以省略 代码如下：CarDao.java12345678910111213141516@Repositorypublic class CarDao &#123; private String label = "11111"; public String getLabel() &#123; return label; &#125; public void setLabel(String label) &#123; this.label = label; &#125; @Override public String toString() &#123; return "CarDao&#123;" + "label='" + label + '\'' + '&#125;'; &#125;&#125; CarService.java12345678910111213@Servicepublic class CarService &#123; @Qualifier("carDao2")// @Autowired(required = false)// @Autowired private CarDao carDao; @Override public String toString() &#123; return "CarService&#123;" + "carDao=" + carDao + '&#125;'; &#125;&#125; 测试类MainConfig.java1234567891011@Configuration//@ComponentScan(&#123;"com.zero.controller","com.zero.service","com.zero.dao"&#125;)public class MainConfig &#123;// @Primary @Bean("carDao2") public CarDao carDao()&#123; CarDao carDao = new CarDao(); carDao.setLabel("22"); return carDao; &#125;&#125; Spring还支持使用@Resource(JSR250)和@Inject(JSR330)@Resource: 可以和@AutoWired一样实现自动装配功能：默认是按照组件【名称】进行装配的。 没有能支持@Primary功能没有支持@Autowired(required=false); @Injecct 需要导入javax.inject的包，和autowired的功能一样，没有required=false的功能； @AutoWired：spring定义的； @Resource、@Inject都是java规范 AutowiredAnnotationBeanPostProcessor：解析完成自动装配功能； 自定义组件想要使用spring容器底层的一些组件（ApplicationContext、BeanFactory、xxxx）自定义组件实现xxxAware:在创建对象的时候，会调用接口规定的方法注入相关组件： Aware：把spring底层的一些组件注入到自定义的Bean中 ApplicationContextAware ===&gt; ApplicationContextAwareProcessor; @Profile:指定组件在哪个环境的情况下才能被注册到容器中，不指定，任何环境都能注册这个组件。 a、加了环境标识bean，只有这个环境被激活的时候才能注册到容器中，默认是default环境 b、写在配置类上，只有是指定的环境的时候，整个配置类里面所有配置才能开始生效。 c、没有标注环境标识的bean在任何环境下都加载的。 示例代码如下： 123456789101112131415161718192021222324252627282930@Configuration//@ComponentScan(&#123;"com.zero.controller","com.zero.service","com.zero.dao"&#125;)public class MainConfig &#123;// @Primary @Bean("carDao2") public CarDao carDao()&#123; CarDao carDao = new CarDao(); carDao.setLabel("22"); return carDao; &#125; @Profile("test") @Bean public NiuBean niuBean()&#123; return new NiuBean(); &#125; @Profile("dev") @Bean public CatBean catBean()&#123; return new CatBean(); &#125; @Profile("prod") @Bean public DogBean dogBean()&#123; return new DogBean(); &#125;&#125; 测试类：12345678910111213141516171819@Testpublic void testProfile()&#123; //1.创建一个applicationContext AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(); //2.设置需要激活的环境 applicationContext.getEnvironment().setActiveProfiles("test"); //3.注册主配置类 applicationContext.register(MainConfig.class); //4.启动刷新容器 applicationContext.refresh(); String[] definitionNames = applicationContext.getBeanDefinitionNames(); for (String name: definitionNames) &#123; System.out.println(name); &#125;&#125;]]></content>
      <categories>
        <category>Spring源码</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring属性赋值]]></title>
    <url>%2F2018%2F10%2F14%2FSpring%E5%B1%9E%E6%80%A7%E8%B5%8B%E5%80%BC%2F</url>
    <content type="text"><![CDATA[@Value支持三种方式： 基本数值 可以写SpEL: #{} 可以写${},去配置文件【properties】中的值 代码如下： Girl.java实体类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class Girl &#123; //使用@Value赋值 //1. 基本数值 //2. 可以写SpEL: #&#123;&#125; //3.可以写$&#123;&#125;,去配置文件【properties】中的值（在运行环境变量里的值） @Value("NAME") private String name; @Value("#&#123;65+8&#125;") private Integer age; @Value("$&#123;ggg&#125;") private String weiXin; public Girl() &#123; &#125; public Girl(String name, Integer age) &#123; this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; public String getWeiXin() &#123; return weiXin; &#125; public void setWeiXin(String weiXin) &#123; this.weiXin = weiXin; &#125; @Override public String toString() &#123; return "Girl&#123;" + "name='" + name + '\'' + ", age=" + age + ", weiXin='" + weiXin + '\'' + '&#125;'; &#125;&#125; @PropertySource加载配置文件MainConfig_properties.java1234567891011//使用PropertySource读取外部配置文件中的k/v保存到环境变量中@PropertySource(value = &#123;"classpath:/person.properties"&#125;)@Configurationpublic class MainConfig_properties &#123; @Bean public Girl girl()&#123; return new Girl(); &#125;&#125; person.properties12xixixii=gjdkjgkjdggg=sgfsdfsd]]></content>
      <categories>
        <category>Spring源码</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring生命周期]]></title>
    <url>%2F2018%2F10%2F14%2FSpring%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%2F</url>
    <content type="text"><![CDATA[@Bean初始化和销毁bean的生命周期：&emsp;&emsp;bean创建—–初始化—–销毁的过程 容器管理bean的生命周期： &emsp;&emsp;我们可以自定义初始化和销毁方法：容器在bean进行到当前生命周期的时候来调用我们自定义的初始化和销毁方法。 &emsp;构造函数： &emsp;单实例：容器创建时进行初始化 &emsp;多实例：在每次获取的时候创建对象 BeanPostProcessor.postProcessBeforeInitialization 初始化： &emsp;对象创建完成，并赋值好，调用初始化方法。 BeanPostProcessor.postProcessAfterInitialization 销毁： &emsp;单实例：容器关闭的时候 &emsp;多实例：容器不会管理这个bean；容器不会调用销毁方法； 1、指定初始化和销毁方法 &emsp;通过@Bean指定init-method和destroy-method； 2、通过Bean实现InitializingBean(定义初始化逻辑)&emsp;&emsp;DisposableBean(定义销毁逻辑) 3、可以使用JSR250规范： &emsp;@PostConstruct:在bean创建完成并且属性赋值完成 &emsp;@PreDestroy：在容器销毁bean销毁之前调用清理工作 代码如下： a. initMethod 和destroyMethod 的使用MainConfig.java123456789101112@Configuration@ComponentScan("com.zero.life")public class MainConfig &#123;// @Scope("prototype") @Bean(initMethod = "init",destroyMethod = "destroy") public Phone phone()&#123; return new Phone(); &#125;&#125; Phone.java12345678910111213141516public class Phone &#123; public Phone() &#123; System.out.println("Phone初始化构造。。。"); &#125; public void init()&#123; System.out.println("Phone 初始化方法。。。。"); &#125; public void destroy()&#123; System.out.println("Phone 销毁方法。。。"); &#125;&#125; b. InitializingBean和DisposableBean 的使用 123456789101112131415@Componentpublic class Android implements InitializingBean,DisposableBean &#123; public Android() &#123; System.out.println("android constructor......."); &#125; @Override public void destroy() throws Exception &#123; System.out.println("android destroy........"); &#125; @Override public void afterPropertiesSet() throws Exception &#123; System.out.println("android afterPropertiesSet........"); &#125;&#125; c. @PostConstruct和@PreDestroy的使用12345678910111213141516171819@Componentpublic class AIIphone &#123; public AIIphone() &#123; System.out.println("AIIphone.... contruct..."); &#125; @PostConstruct public void init()&#123; System.out.println("AIIphone.....PostConstruct"); &#125; @PreDestroy public void destroy()&#123; System.out.println("AIIphone......PreDestroy"); &#125;&#125; BeanPostProcessor后置处理器BeanPostProcessor【interface】： bean的后置处理器：在bean初始化前后进行一些处理工作。 &emsp;1. postProcessBeforeInitialization:在初始化之前工作 &emsp;2. postProcessAfterInitialization:在初始化之后工作 12345678910111213141516171819/** * 后置处理器，初始化前后进行处理工作 */@Componentpublic class MyBeanPostProcessor implements BeanPostProcessor &#123; @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; System.out.println("postProcessBeforeInitialization....."+beanName+"=&gt;"+bean); return bean;//可对bean进行包装后返回 &#125; @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; System.out.println("postProcessAfterInitialization....."+beanName+"=&gt;"+bean); return bean;//可对bean进行包装后返回 &#125;&#125;]]></content>
      <categories>
        <category>Spring源码</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[spring组件注册]]></title>
    <url>%2F2018%2F10%2F14%2Fspring%E7%BB%84%E4%BB%B6%E6%B3%A8%E5%86%8C%2F</url>
    <content type="text"><![CDATA[@Configuration和@Bean @Configuration作用：告诉spring是个配置类 @Bean作用：给容器中注册一个Bean;类型就是返回值类型。id默认为方法名。例如 @Bean(“xixix”) //指定为xixix，修改name @ComponentScan @ComponentScan(“com.zero”) //自动扫描@Controller、@Service、@Repository excludeFilters:指定扫描的时候按照什么规则排除哪些组件 includeFilters：指定扫描的时候只需包含哪些组件。使用时需要禁用默认的全扫描useDefaultFilters = false 12345678910111213141516171819202122232425//配置类@Configuration //告诉spring是个配置类//@ComponentScan("com.zero") //自动扫描@Controller、@Service、@Repository//可以排除哪些注解不扫描。//excludeFilters:指定扫描的时候按照什么规则排除哪些组件//includeFilters：指定扫描的时候只需包含哪些组件。使用时需要禁用默认的全扫描useDefaultFilters = false//FilterType.ANNOTATION 按照注解//FilterType.ASSIGNABLE_TYPE 按照给定的类型//FilterType.ASPECTJ 使用ASPECTJ表达式//FilterType.REGEX 使用正则表达式//FilterType.CUSTOM 使用自定义规则@ComponentScan(value = "com.zero", includeFilters = &#123;// @ComponentScan.Filter(type = FilterType.ANNOTATION,classes = &#123;Controller.class, Service.class&#125;)//&#125;, @ComponentScan.Filter(type = FilterType.CUSTOM, classes = &#123;MyTypeFilter.class&#125;)&#125;, useDefaultFilters = false)public class MainConfig &#123; //@Bean 给容器中注册一个Bean;类型就是返回值类型。id默认为方法名 @Bean("xixix") //指定为xixix，修改name public Cat cat() &#123; return new Cat("kathyrn", "skdjf", "girl"); &#125;&#125; MyTypeFilter.java 自定义过滤规则 12345678910111213141516171819202122232425/***自定义过滤规则**/public class MyTypeFilter implements TypeFilter &#123; @Override public boolean match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory) throws IOException &#123; AnnotationMetadata annotationMetadata = metadataReader.getAnnotationMetadata(); ClassMetadata classMetadata = metadataReader.getClassMetadata(); Resource resource = metadataReader.getResource(); String className = classMetadata.getClassName(); System.out.println("----&gt;"+className); if (className.contains("er"))&#123;//自定义的过滤规则 return true;//匹配成功则返回可扫描。 &#125; return false; &#125;&#125; @Scope和@Lazy3.1 @Scope作用： prototype：多实例，每次获取的时候才会创建对象，而且每次获取重新new一次。 singleton：单实例（默认值），ioc容器启动会调用方法创建ioc容器中，以后每次获取就是直接从容器（map.get()）中拿 3.2 @Lazy作用：懒加载：单实例容器启动时不创建对象，直到第一次获取bean时才创建对象。 1234567891011121314151617//默认是单实例的/** * ConfigurableBeanFactory#SCOPE_PROTOTYPE 多实例 * ConfigurableBeanFactory#SCOPE_SINGLETON 单实例 * org.springframework.web.context.WebApplicationContext#SCOPE_REQUEST * org.springframework.web.context.WebApplicationContext#SCOPE_SESSION * prototype：多实例，每次获取的时候才会创建对象，而且每次获取重新new一次。 * singleton：单实例（默认值），ioc容器启动会调用方法创建ioc容器中，以后每次获取就是直接从容器（map.get()）中拿 * */@Lazy //懒加载：单实例容器启动时不创建对象，直到第一次获取bean时才创建对象。@Scope("singleton")@Bean("cat")public Cat cat()&#123; System.out.println("新建了bean。。。。。。。。。。"); return new Cat("xixi","xigjd","girl");&#125; @Conditional@Conditional按条件进行加载Bean LinuxCondition.java12345678910111213141516171819202122232425262728293031public class LinuxCondition implements Condition &#123; /** * ConditionContext 判断条件能使用的上下文 * AnnotatedTypeMetadata 注释信息。 * @param context * @param metadata * @return */ @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; //1.能获取ioc使用的beanFactory ConfigurableListableBeanFactory beanFactory = context.getBeanFactory(); //2.获取类加载器 ClassLoader classLoader = context.getClassLoader(); //3.获取当前环境信息 Environment environment = context.getEnvironment(); //4.获取到bean定义的注册类 BeanDefinitionRegistry registry = context.getRegistry(); String property = environment.getProperty("os.name"); if (property.contains("Linux"))&#123; return true; &#125; return false; &#125;&#125; WindowsCondition.java1234567891011121314151617181920212223242526272829303132public class WindowsCondition implements Condition &#123; /** * ConditionContext 判断条件能使用的上下文 * AnnotatedTypeMetadata 注释信息。 * @param context * @param metadata * @return */ @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; //1.能获取ioc使用的beanFactory ConfigurableListableBeanFactory beanFactory = context.getBeanFactory(); //2.获取类加载器 ClassLoader classLoader = context.getClassLoader(); //3.获取当前环境信息 Environment environment = context.getEnvironment(); //4.获取到bean定义的注册类 BeanDefinitionRegistry registry = context.getRegistry(); String property = environment.getProperty("os.name"); if (property.contains("Windows"))&#123; return true; &#125; return false; &#125;&#125; 注入相关类。12345678910111213141516@Conditional(&#123;WindowsCondition.class&#125;)@Bean("bill")public Cat cat1() &#123; System.out.println("给容器中添加cat。。。。。"); return new Cat("34","Bill Gates","boy");&#125;@Conditional(&#123;LinuxCondition.class&#125;)@Bean("linux")public Cat cat2() &#123; System.out.println("给容器中添加cat。。。。。"); return new Cat("112","linux","girl");&#125; @Import、ImportSelector、ImportBeanDefinition、FactoryBean@Import[快速给容器中导一个组件] a) @Import（需要导入到容器中的组件）：容器入就会自动注册该组件 b) @ImportSelector:返回需要导入的组件的全类名 c)@ImportBeanDefinitions 123456@Configuration@Import(&#123;Color.class, Red.class, MyImportSelector.class&#125;)//@Import导入组件、id默认是组件的全类名public class MainConfig &#123; ......&#125; 使用ImportSelector12345678public class MyImportSelector implements ImportSelector &#123; //返回值，就是导入到容器中的组件的全类名 //AnnotationMetadata：当前标注@Import注解的所有注解信息。 @Override public String[] selectImports(AnnotationMetadata importingClassMetadata) &#123; return new String[]&#123;"com.zero.bean.Blue"&#125;; &#125;&#125; 使用ImportBeanDefinition123456789101112131415161718192021222324public class MyImportBeanDefinitions implements ImportBeanDefinitionRegistrar &#123; /** * AnnotationMetadata： 当前类的注解注册信息 * BeanDefinitionRegistry：BeanDefinition注册类 * 把所有需要添加到容器中的bean，调用BeanDefinitionRegistry的registerBeanDefinition方法 * 进行手工注册。 * @param importingClassMetadata * @param registry */ @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; boolean red = registry.containsBeanDefinition("com.zero.bean.Red"); boolean blue = registry.containsBeanDefinition("com.zero.bean.Blue"); if (red &amp;&amp; blue) &#123; RootBeanDefinition rootBeanDefinition = new RootBeanDefinition(Rainbow.class); registry.registerBeanDefinition("rainBow",rootBeanDefinition); &#125; &#125;&#125; 使用spring提供的FactoryBean(工厂Bean); a) 默认获取到的是工厂Bean调用getObject创建的对象 b) 要获取工厂Bean本身，我们需要给id前面加一个&amp;，例如 &amp;colorFactoryBean FactoryBean的方式进行加载12345678910111213141516171819202122public class ColorFactoryBean implements FactoryBean&lt;Color&gt;&#123; //返回一个Color对象，这个对象会添加到容器中 @Override public Color getObject() throws Exception &#123; return new Color(); &#125; @Override public Class&lt;?&gt; getObjectType() &#123; return Color.class; &#125; //是单例？ //true：这个bean是单实例的,在容器中保存一份。 //false：多实例，每次获取都会创建一个实例。 @Override public boolean isSingleton() &#123; return true; &#125;&#125; 将javaBean注入到容器中1234@Beanpublic ColorFactoryBean colorFactoryBean()&#123; return new ColorFactoryBean();&#125; 总结 给容器中注册组件 @ComponentScan包扫描+组件标注注解（@Controller/@Service/@Repository/@Compoment） @Bean[导入第三方包里面的组件] @Import[快速给容器中导一个组件], a) @Import（需要导入到容器中的组件）：容器入就会自动注册该组件 b) @ImportSelector:返回需要导入的组件的全类名 c) @ImportBeanDefinitions 使用spring提供的FactoryBean(工厂Bean); a) 默认获取到的是工厂Bean调用getObject创建的对象 b) 要获取工厂Bean本身，我们需要给id前面加一个&amp;，例如&amp;colorFactoryBean]]></content>
      <categories>
        <category>Spring源码</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring入门]]></title>
    <url>%2F2018%2F10%2F07%2Fspring%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[spring的简单使用1.1. javaBean123456789101112public class MyTestBean &#123; private String testStr ="testStr"; public String getTestStr()&#123; return testStr; &#125; public void setTestStr(String testStr)&#123; this.testStr = testStr; &#125;&#125; 1.2. xml配置12345678910&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;bean id="myTestBean" class="com.zero.entity.MyTestBean"&gt;&lt;/bean&gt; &lt;!-- ... --&gt;&lt;/beans&gt; 1.3. 测试12345678910111213public class TestBean &#123; @Test public void testSimpleLoad()&#123; //1.读取配置文件bean.xml BeanFactory bf = new XmlBeanFactory(new ClassPathResource("com/zero/bean.xml")); //2. 根据配置文件找到对应的类的配置，并实例化 MyTestBean bean = (MyTestBean) bf.getBean("myTestBean"); //调用实例化后的实例 assertEquals("testStr",bean.getTestStr()); &#125;&#125; 以上三步就完成了spring的基本用法。 分析2.1 XmlBeanFactory分析 AliasRegistry:定义对alias的简单增删该操作等。 SimpleAliasRegistry:主要使用map作为alias的缓存，并对接口AliasRegistry进行实现。 SingletonBeanRegistry:定义对单例的注册及获取。 BeanFactory: 定义获取bean及bean的各种属性。 DefaultSingletonBeanRegistry:对接口SingletonBeanRegistry各函数的实现。 HierarchicalBeanFactory：继承BeanFactory，也就是在BeanFactory定义的功能的基础上增加了对parentFacotry的支持。 BeanDefinitionRegistry：定义对BeanDefinition的各种增删改操作。 FactoryBeanRegistrySupport：在DefaultSingletonBeanRegistry基础上增加了对FactoryBean的特殊处理功能。 ConfigurableBeanFactory：提供配置Factory的各种方法。 ListableBeanFactory:根据各种条件获取bean的配置清单。 AbstractBeanFactory:综合FactoryBeanRegistrySupport和ConfigurableBeanFactory的功能。 AutowireCapableBeanFactory:提供创建bean、自动注入、初始化以及应用bean的后处理器。 AbstractAutowireCapableBeanFactory:综合AbstractBeanFactory并对接口AutowireCapableBeanFactory进行实现。 ConfigurableListableBeanFactory:BeanFactory配置清单，指定忽略类型及接口等。 DefaultListableBeanFactory:综合上面所有的功能，主要是对bean注册后的处理。 xmlBeanFactory中主要使用reader属性对资源文件进行读取和注册。 2.2 XmlBeanDefinitionReader分析 BeanDefinitionReader:主要定义资源文件读取并转换为BeanDefinition的各个功能。 EnvironmentCapable:定义获取Environment方法。 AbstractBeanDefinitionReader：对EnvironmentCapable、BeanDefinitionReader类定义的功能进行实现。]]></content>
      <categories>
        <category>Spring源码</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之观察和代理]]></title>
    <url>%2F2018%2F09%2F29%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A7%82%E5%AF%9F%E5%92%8C%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[观察者模式其实就是发布订阅模式，发布者发布信息，订阅者获取信息，订阅了就能收到信息，没订阅就收不到信息。 1.1 抽象被观察者角色：也就是一个抽象主题，它把所有对观察者对象的引用保存在一个集合中，每个主题都可以有任意数量的观察者。抽象主题提供一个接口，可以增加和删除观察者角色。一般用一个抽象类和接口来实现。 1.2 抽象观察者角色：为所有的具体观察者定义一个接口，在得到主题通知时更新自己。 1.3 具体被观察者角色：也就是一个具体的主题，在集体主题的内部状态改变时，所有登记过的观察者发出通知。 1.4 具体观察者角色：实现抽象观察者角色所需要的更新接口，一边使本身的状态与制图的状态相协调。 123456789101112131415public interface Subject &#123; /*增加观察者*/ public void add(Observer observer); /*删除观察者*/ public void del(Observer observer); /*通知所有的观察者*/ public void notifyObservers(); /*自身的操作*/ public void operation();&#125; 12345678910111213141516171819202122public abstract class AbstractSubject implements Subject &#123; private Vector&lt;Observer&gt; vector = new Vector&lt;&gt;(); @Override public void add(Observer observer) &#123; vector.add(observer); &#125; @Override public void del(Observer observer) &#123; vector.remove(observer); &#125; @Override public void notifyObservers() &#123; Enumeration&lt;Observer&gt; enumeration = vector.elements(); while (enumeration.hasMoreElements())&#123; enumeration.nextElement().update(); &#125; &#125;&#125; 123public interface Observer &#123; public void update();&#125; 123456public class Observer1 implements Observer &#123; @Override public void update() &#123; System.out.println("observer1 have received!"); &#125;&#125; 123456public class Observer2 implements Observer &#123; @Override public void update() &#123; System.out.println("observer2 has received"); &#125;&#125; 12345678910public class Test &#123; public static void main(String[] args) &#123; Subject sub = new MySubject(); sub.add(new Observer1()); sub.add(new Observer2()); sub.operation(); &#125;&#125; 代理模式代理模式的定义：代理模式给某一个对象提供一个代理对象，并由代理对象控制对原对象的引用。通俗的来讲代理模式就是我们生活中常见的中介。 举个例子来说明：假如说我现在想买一辆二手车，虽然我可以自己去找车源，做质量检测等一系列的车辆过户流程，但是这确实太浪费我得时间和精力了。我只是想买一辆车而已为什么我还要额外做这么多事呢？于是我就通过中介公司来买车，他们来给我找车源，帮我办理车辆过户流程，我只是负责选择自己喜欢的车，然后付钱就可以了。 分类 静态代理是创建或特定工具自动生成源代码，在对其编译。在程序运行之前，代理类.class文件就已经被创建了。 动态代理是在程序运行时通过反射机制动态创建的。 静态代理实现123public interface Sourceable &#123; public void method();&#125; 123456public class Source implements Sourceable &#123; @Override public void method() &#123; System.out.println("the original method!"); &#125;&#125; 1234567891011121314151617181920212223public class Proxy implements Sourceable &#123; private Source source; public Proxy() &#123; super(); this.source = new Source(); &#125; @Override public void method() &#123; before(); source.method(); atfer(); &#125; private void atfer() &#123; System.out.println("after proxy!"); &#125; private void before() &#123; System.out.println("before proxy!"); &#125;&#125; 1234567public class Test &#123; public static void main(String[] args) &#123; Sourceable sourceable = new Proxy(); sourceable.method(); &#125;&#125; 动态代理实现(JDK)12345678910111213141516public class DynamicProxyHandler implements InvocationHandler &#123; private Object object; public DynamicProxyHandler(final Object object) &#123; this.object = object; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println("买房前准备"); Object result = method.invoke(object, args); System.out.println("买房后装修"); return result; &#125;&#125; 12345678public class DynamicProxyTest &#123; public static void main(String[] args) &#123; BuyHouse buyHouse = new BuyHouseImpl(); BuyHouse proxyBuyHouse = (BuyHouse) Proxy.newProxyInstance(BuyHouse.class.getClassLoader(), new Class[]&#123;BuyHouse.class&#125;, new DynamicProxyHandler(buyHouse)); proxyBuyHouse.buyHosue(); &#125;&#125; 动态代理实现(CGLIB代理)1234567891011121314151617public class CglibProxy implements MethodInterceptor &#123; private Object target; public Object getInstance(final Object target) &#123; this.target = target; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(this.target.getClass()); enhancer.setCallback(this); return enhancer.create(); &#125; public Object intercept(Object object, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; System.out.println("买房前准备"); Object result = methodProxy.invoke(object, args); System.out.println("买房后装修"); return result; &#125;&#125; 12345678public class CglibProxyTest &#123; public static void main(String[] args)&#123; BuyHouse buyHouse = new BuyHouseImpl(); CglibProxy cglibProxy = new CglibProxy(); BuyHouseImpl buyHouseCglibProxy = (BuyHouseImpl) cglibProxy.getInstance(buyHouse); buyHouseCglibProxy.buyHosue(); &#125;&#125; 总结：CGLIB创建的动态代理对象比JDK创建的动态代理对象的性能更高，但是CGLIB创建代理对象时所花费的时间却比JDK多得多。所以对于单例的对象，因为无需频繁创建对象，用CGLIB合适，反之使用JDK方式要更为合适一些。同时由于CGLib由于是采用动态创建子类的方法，对于final修饰的方法无法进行代理。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[设计模式之命令和模板]]></title>
    <url>%2F2018%2F09%2F29%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%91%BD%E4%BB%A4%E5%92%8C%E6%A8%A1%E6%9D%BF%2F</url>
    <content type="text"><![CDATA[命令模式经典的命令模式包括4个角色： Command：定义命令的统一接口 ConcreteCommand：Command接口的实现者，用来执行具体的命令，某些情况下可以直接用来充当Receiver。 Receiver：命令的实际执行者 Invoker：命令的请求者，是命令模式中最重要的角色。这个角色用来对各个命令进行控制。123456/** * 口令 */public interface Command &#123; public void exe();&#125; 123456789101112/** * 老板 */public class Invoker &#123; private Command command; public Invoker(Command command) &#123; this.command = command; &#125; public void action()&#123; command.exe(); &#125;&#125; 12345678/** * 打工仔 */public class Receiver &#123; public void action()&#123; System.out.println("command received!"); &#125;&#125; 123456789public class Test &#123; public static void main(String[] args) &#123; Receiver receiver = new Receiver(); Command command = new MyCommand(receiver); Invoker invoker = new Invoker(command); invoker.action(); &#125;&#125; 模板模式 定义：一个操作中算法的骨架，而将一些步骤延迟到子类中，模板方法使得子类可以不改变算法的结构即可重定义该算法的某些特定步骤。通俗点的理解就是 ：完成一件事情，有固定的数个步骤，但是每个步骤根据对象的不同，而实现细节不同；就可以在父类中定义一个完成该事情的总方法，按照完成事件需要的步骤去调用其每个步骤的实现方法。每个步骤的具体实现，由子类完成。 实例： 来举个例子： 比如我们做菜可以分为三个步骤 （1）备料 （2）具体做菜 （3）盛菜端给客人享用，这三部就是算法的骨架 ；然而做不同菜需要的料，做的方法，以及如何盛装给客人享用都是不同的这个就是不同的实现细节。 a. 先来写一个抽象的做菜父类：12345678910111213141516171819202122public abstract class DodishTemplate &#123; /** * 具体的整个过程 */ protected void dodish()&#123; this.preparation(); this.doing(); this.carriedDishes(); &#125; /** * 备料 */ public abstract void preparation(); /** * 做菜 */ public abstract void doing(); /** * 上菜 */ public abstract void carriedDishes ();&#125; b. 下来做两个番茄炒蛋（EggsWithTomato）和红烧肉（Bouilli）实现父类中的抽象方法12345678910111213141516171819202122/** * 红烧肉 * */public class Bouilli extends DodishTemplate&#123; @Override public void preparation() &#123; System.out.println("切猪肉和土豆。"); &#125; @Override public void doing() &#123; System.out.println("将切好的猪肉倒入锅中炒一会然后倒入土豆连炒带炖。"); &#125; @Override public void carriedDishes() &#123; System.out.println("将做好的红烧肉盛进碗里端给客人吃。"); &#125;&#125; 123456789101112131415161718192021/** * 西红柿炒蛋 */public class EggsWithTomato extends DodishTemplate&#123; @Override public void preparation() &#123; System.out.println("洗并切西红柿，打鸡蛋。"); &#125; @Override public void doing() &#123; System.out.println("鸡蛋倒入锅里，然后倒入西红柿一起炒。"); &#125; @Override public void carriedDishes() &#123; System.out.println("将炒好的西红寺鸡蛋装入碟子里，端给客人吃。"); &#125;&#125; c. 在测试类中我们来做菜：1234567891011public class App &#123; public static void main(String[] args) &#123; DodishTemplate eggsWithTomato = new EggsWithTomato(); eggsWithTomato.dodish(); System.out.println("-----------------------------"); DodishTemplate bouilli = new Bouilli(); bouilli.dodish(); &#125;&#125; 总结模板模式的优点 （1）具体细节步骤实现定义在子类中，子类定义详细处理算法是不会改变算法整体结构。 （2）代码复用的基本技术，在数据库设计中尤为重要。 （3）存在一种反向的控制结构，通过一个父类调用其子类的操作，通过子类对父类进行扩展增加新的行为，符合“开闭原则”。不足 （1）每个不同的实现都需要定义一个子类，会导致类的个数增加，系统更加庞大。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[设计模式之适配和装饰]]></title>
    <url>%2F2018%2F09%2F29%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E9%80%82%E9%85%8D%E5%92%8C%E8%A3%85%E9%A5%B0%2F</url>
    <content type="text"><![CDATA[适配器模式 通过一个简单的例子说一下适配器模式，适配器模式属于接口型模式。适配器模式的意图在于，使用不同接口的类所提供的服务为客户端提供。123456/** * Android规格的充电头 */public interface AndroidCharge &#123; void isAndroidHeader();&#125; 123456/** * 苹果手机的插头规格 */public interface IphoneCharge &#123; void isIphoneHeader();&#125; 123456public class AndroidPhone implements AndroidCharge &#123; @Override public void isAndroidHeader() &#123; System.out.println("Andorid充电头"); &#125;&#125; 123456789/** * 类适配器模式，将你手上的iPhone充电头适配成Android的充电头。 */public class Adapter extends AndroidPhone implements IphoneCharge &#123; @Override public void isIphoneHeader() &#123; isAndroidHeader(); &#125;&#125; 12345678910111213141516/** * 对象适配器 */public class Adapter2 implements IphoneCharge &#123; private AndroidCharge androidCharge; public Adapter2(AndroidCharge androidCharge) &#123; this.androidCharge = androidCharge; &#125; @Override public void isIphoneHeader() &#123; androidCharge.isAndroidHeader(); &#125;&#125; 1234567public class Test &#123; public static void main(String[] args) &#123; IphoneCharge p = new Adapter(); ((Adapter) p).isAndroidHeader(); &#125;&#125; 装饰者模式装饰者模式: 动态地将责任附加到对象上,对扩展功能来说,装饰者比继承更有弹性更灵活(因为子类继承父类扩展功能的前提,是已知要扩展的功能是什么样的,而这是在编译时就要确定的,但是装饰者模式可以实现动态(在运行时)去扩展功能). 比如有一个可乐对象,那我用一个加冰对象装饰一下,再用加糖对象装饰一下,最后能得到一个加冰加糖可乐,这时候就将原可乐对象扩展,得到了加冰和加糖两种装饰. 1234567891011public abstract class Drink &#123; String name; public abstract int price(); public String getName() &#123; return name; &#125;&#125; 1234567891011public class CocaCola extends Drink&#123; public CocaCola() &#123; name = "Coca Cola"; &#125; @Override public int price() &#123; return 30; &#125;&#125; 1234567891011public class Beer extends Drink &#123; public Beer() &#123; name="Beer"; &#125; @Override public int price() &#123; return 6; &#125;&#125; 12345678public abstract class Decorator extends Drink&#123; protected Drink drink; public Decorator(Drink drink) &#123; this.drink = drink; &#125;&#125; 12345678910111213141516171819202122public class VinegarDecorator extends Decorator &#123; public VinegarDecorator(Drink drink) &#123; super(drink); &#125; public void addVinegar()&#123; System.out.println("加醋"); &#125; @Override public int price() &#123; return 5+drink.price(); &#125; @Override public String getName() &#123; return "加醋的"+drink.getName(); &#125;&#125; 123456789101112131415161718192021public class WaterDecorator extends Decorator &#123; public WaterDecorator(Drink drink) &#123; super(drink); &#125; public void addWater()&#123; System.out.println("饮料兑水"); &#125; @Override public int price() &#123; return 2+drink.price(); &#125; @Override public String getName() &#123; addWater(); return "兑水了的"+drink.getName(); &#125;&#125; 12345678910public class Test &#123; public static void main(String[] args) &#123; Drink drink = new CocaCola(); drink = new WaterDecorator(drink); drink = new VinegarDecorator(drink); System.out.println(drink.getName()+"---价格："+drink.price()); &#125;&#125;]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[设计模式之工厂和建造]]></title>
    <url>%2F2018%2F09%2F29%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%B7%A5%E5%8E%82%E5%92%8C%E5%BB%BA%E9%80%A0%2F</url>
    <content type="text"><![CDATA[工厂模式抽象工厂模式，创建多个工厂类，这样一旦需要增加新的功能，直接增加新的工厂类就可以了，不需要修改之前的代码。123public interface Sender &#123; public void send();&#125; 123public interface Provider &#123; public Sender produce();&#125; 123456public class MailSender implements Sender &#123; @Override public void send() &#123; System.out.println("this is mail"); &#125;&#125; 123456public class WeixinSender implements Sender &#123; @Override public void send() &#123; System.out.println("this is weixin sender"); &#125;&#125; 123456public class SendMailFactory implements Provider &#123; @Override public Sender produce() &#123; return new MailSender(); &#125;&#125; 123456public class SendWeixinFactory implements Provider &#123; @Override public Sender produce() &#123; return new WeixinSender(); &#125;&#125; 12345678public class Test &#123; public static void main(String[] args) &#123; Provider provider = new SendWeixinFactory(); Sender sender = provider.produce(); sender.send(); &#125;&#125; 建造者模式工厂类模式提供的是创建单个类的模式，而建造者模式则是将各种产品集中起来进行管理，用来创建复合对象，所谓复合对象就是指某个类具有不同的属性，其实建造者模式就是前面抽象工厂模式和最后的Test结合起来得到的。 建造者模式将很多功能集成到一个类里，这个类可以创造出比较复杂的东西。所以与工程模式的区别就是：工厂模式关注的是创建单个产品，而建造者模式则关注创建符合对象，多个部分。 1234567891011/** * 工作过程 */public abstract class Builder &#123; public abstract void openEye(); public abstract void eatFood(); public abstract void doWork();&#125; 12345678910111213141516171819202122232425/** *打工仔 */public class ConcreteBuilder extends Builder &#123; Person worker = new Person(); @Override public void openEye() &#123; worker.Add("睁开眼"); &#125; @Override public void eatFood() &#123; worker.Add("吃饭"); &#125; @Override public void doWork() &#123; worker.Add("敲代码"); &#125; public Person getWorker() &#123; return worker; &#125;&#125; 1234567891011/** * 包工头 */public class Director &#123; public void construct(Builder builder)&#123; builder.openEye(); builder.eatFood(); builder.doWork(); &#125;&#125; 12345678910111213141516171819202122/** * 干活的人，就是你（其中的一个打工仔） */public class Person &#123; //日常生活流程 private List&lt;String&gt; parts = new ArrayList&lt;String&gt;(); //记录每天日常 public void Add(String part)&#123; parts.add(part); &#125; public void Show()&#123; for (int i = 0;i&lt;parts.size();i++)&#123; System.out.println("开始了"+parts.get(i)); &#125; System.out.println("sleep,good night"); &#125;&#125; 123456789101112public class Test &#123; public static void main(String[] args) &#123; Director director = new Director(); Builder builder = new ConcreteBuilder(); director.construct(builder); Person person = ((ConcreteBuilder) builder).getWorker(); person.Show(); &#125;&#125;]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[设计模式之单例]]></title>
    <url>%2F2018%2F09%2F29%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[设计模式的分类总体来说设计模式分为三大类： 创建型模式，共五种：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式。 结构型模式，共七种：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。 行为型模式，共十一种：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 设计模式的六大原则 开闭原则（Open Close Principle） 里氏代换原则（Liskov Substitution Principle） 依赖倒转原则（Dependence Inversion Principle） 接口隔离原则（Interface Segregation Principle） 迪米特法则（最少知道原则）（Demeter Principle） 合成复用原则（Composite Reuse Principle） 设计模式实现单例模式单例对象（Singleton）是一种常用的设计模式。在Java应用中，单例对象能保证在一个JVM中，该对象只有一个实例存在。 饿汉模式优点：这种写法比较简单，就是在类装载的时候就完成实例化。避免了线程同步问题。缺点：在类装载的时候就完成实例化，没有达到Lazy Loading的效果。如果从始至终从未使用过这个实例，则会造成内存的浪费。 12345678910111213/** * 饿汉模式（可用） */public class EHanSingleton &#123; private static EHanSingleton instance = new EHanSingleton(); private EHanSingleton()&#123; &#125; public static EHanSingleton getInstance()&#123; return instance; &#125;&#125; 静态内部类这种方式跟饿汉式方式采用的机制类似，但又有不同。两者都是采用了类装载的机制来保证初始化实例时只有一个线程。不同的地方在饿汉式方式是只要Singleton类被装载就会实例化，没有Lazy-Loading的作用，而静态内部类方式在Singleton类被装载时并不会立即实例化，而是在需要实例化时，调用getInstance方法，才会装载SingletonInstance类，从而完成Singleton的实例化。类的静态属性只会在第一次加载类的时候初始化，所以在这里，JVM帮助我们保证了线程的安全性，在类进行初始化时，别的线程是无法进入的。优点：避免了线程不安全，延迟加载，效率高。 123456789101112131415/** * 静态内部类（推荐） */public class InnerSingleton &#123; private InnerSingleton()&#123; &#125; private static class InnerSingletonHolder&#123; private final static InnerSingleton instance = new InnerSingleton(); &#125; public static InnerSingleton getInstance()&#123; return InnerSingletonHolder.instance; &#125;&#125; 双重检查我们进行了两次if (singleton == null)检查，这样就可以保证线程安全了。这样，实例化代码只用执行一次，后面再次访问时，判断if (singleton == null)，直接return实例化对象。优点：线程安全；延迟加载；效率较高。 1234567891011121314151617181920/** * 双重检查[推荐用] */public class Singleton &#123; private static volatile Singleton singleton; private Singleton() &#123;&#125; public static Singleton getInstance() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125;]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SparkStreaming入门]]></title>
    <url>%2F2018%2F09%2F28%2FSparkStreaming%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[1.Spark Streaming简介1.1 Spark Streaming 是Spark核心API的一个扩展，可以实现高吞吐量的、具备容错机制的实时流数据的处理。支持从多种数据源获取数据，包括Kafk、Flume、Twitter、ZeroMQ、Kinesis 以及TCP sockets，从数据源获取数据之后，可以使用诸如map、reduce、join和window等高级函数进行复杂算法的处理。最后还可以将处理结果存储到文件系统，数据库和现场仪表盘。在“One Stack rule them all”的基础上，还可以使用Spark的其他子框架，如集群学习、图计算等，对流数据进行处理。 Spark Streaming处理的数据流图： Spark的各个子框架，都是基于核心Spark的，Spark Streaming在内部的处理机制是，接收实时流的数据，并根据一定的时间间隔拆分成一批批的数据，然后通过Spark Engine处理这些批数据，最终得到处理后的一批批结果数据。 对应的批数据，在Spark内核对应一个RDD实例，因此，对应流数据的DStream可以看成是一组RDDs，即RDD的一个序列。通俗点理解的话，在流数据分成一批一批后，通过一个先进先出的队列，然后 Spark Engine从该队列中依次取出一个个批数据，把批数据封装成一个RDD，然后进行处理，这是一个典型的生产者消费者模型，对应的就有生产者消费者模型的问题，即如何协调生产速率和消费速率。 2.一个Demo参考官网的例子123456789101112131415161718192021222324252627282930313233343536373839404142package org.apache.spark.examples.streamingimport org.apache.spark.SparkConfimport org.apache.spark.storage.StorageLevelimport org.apache.spark.streaming.&#123;Seconds, StreamingContext&#125;/** * Counts words in UTF8 encoded, &apos;\n&apos; delimited text received from the network every second. * * Usage: NetworkWordCount &lt;hostname&gt; &lt;port&gt; * &lt;hostname&gt; and &lt;port&gt; describe the TCP server that Spark Streaming would connect to receive data. * * To run this on your local machine, you need to first run a Netcat server * `$ nc -lk 9999` * and then run the example * `$ bin/run-example org.apache.spark.examples.streaming.NetworkWordCount localhost 9999` */object NetworkWordCount &#123; def main(args: Array[String]) &#123; if (args.length &lt; 2) &#123; System.err.println(&quot;Usage: NetworkWordCount &lt;hostname&gt; &lt;port&gt;&quot;) System.exit(1) &#125; StreamingExamples.setStreamingLogLevels() // Create the context with a 1 second batch size val sparkConf = new SparkConf().setAppName(&quot;NetworkWordCount&quot;) val ssc = new StreamingContext(sparkConf, Seconds(1)) // Create a socket stream on target ip:port and count the // words in input stream of \n delimited text (eg. generated by &apos;nc&apos;) // Note that no duplication in storage level only for running locally. // Replication necessary in distributed scenario for fault tolerance. val lines = ssc.socketTextStream(args(0), args(1).toInt, StorageLevel.MEMORY_AND_DISK_SER) val words = lines.flatMap(_.split(&quot; &quot;)) val wordCounts = words.map(x =&gt; (x, 1)).reduceByKey(_ + _) wordCounts.print() ssc.start() ssc.awaitTermination() &#125;&#125; 3.运行demo3.1 使用spark-submit进行发布：命令行运行：1nc -lk 9999 然后提交demo的jar包到sparkStreaming框架中 1234./spark-submit --master local[2] \--class org.apache.spark.examples.streaming.NetworkWordCount \--name NetworkWordCount \/root/app/spark-2.3.0-bin-2.6.0-cdh5.7.0/examples/jars/spark-examples_2.11-2.3.0.jar hadoop01 9999 3.2 使用spark-shell进行发布：123456789./spark-shell --master local[2] \import org.apache.spark.streaming.&#123;Seconds, StreamingContext&#125;val ssc = new StreamingContext(sc, Seconds(1))val lines = ssc.socketTextStream(&quot;hadoop01&quot;, 9999)val words = lines.flatMap(_.split(&quot; &quot;))val wordCounts = words.map(x =&gt; (x, 1)).reduceByKey(_ + _)wordCounts.print()ssc.start()ssc.awaitTermination()]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>SparkStreaming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SparkSQL使用教程]]></title>
    <url>%2F2018%2F09%2F27%2FSparkSQL%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[1.Spark Streaming简介1.1 Spark Streaming 是Spark核心API的一个扩展，可以实现高吞吐量的、具备容错机制的实时流数据的处理。支持从多种数据源获取数据，包括Kafk、Flume、Twitter、ZeroMQ、Kinesis 以及TCP sockets，从数据源获取数据之后，可以使用诸如map、reduce、join和window等高级函数进行复杂算法的处理。最后还可以将处理结果存储到文件系统，数据库和现场仪表盘。在“One Stack rule them all”的基础上，还可以使用Spark的其他子框架，如集群学习、图计算等，对流数据进行处理。 Spark Streaming处理的数据流图： Spark的各个子框架，都是基于核心Spark的，Spark Streaming在内部的处理机制是，接收实时流的数据，并根据一定的时间间隔拆分成一批批的数据，然后通过Spark Engine处理这些批数据，最终得到处理后的一批批结果数据。 对应的批数据，在Spark内核对应一个RDD实例，因此，对应流数据的DStream可以看成是一组RDDs，即RDD的一个序列。通俗点理解的话，在流数据分成一批一批后，通过一个先进先出的队列，然后 Spark Engine从该队列中依次取出一个个批数据，把批数据封装成一个RDD，然后进行处理，这是一个典型的生产者消费者模型，对应的就有生产者消费者模型的问题，即如何协调生产速率和消费速率。 2.一个Demo123456789101112131415161718192021222324252627282930313233343536373839404142package org.apache.spark.examples.streamingimport org.apache.spark.SparkConfimport org.apache.spark.storage.StorageLevelimport org.apache.spark.streaming.&#123;Seconds, StreamingContext&#125;/** * Counts words in UTF8 encoded, &apos;\n&apos; delimited text received from the network every second. * * Usage: NetworkWordCount &lt;hostname&gt; &lt;port&gt; * &lt;hostname&gt; and &lt;port&gt; describe the TCP server that Spark Streaming would connect to receive data. * * To run this on your local machine, you need to first run a Netcat server * `$ nc -lk 9999` * and then run the example * `$ bin/run-example org.apache.spark.examples.streaming.NetworkWordCount localhost 9999` */object NetworkWordCount &#123; def main(args: Array[String]) &#123; if (args.length &lt; 2) &#123; System.err.println(&quot;Usage: NetworkWordCount &lt;hostname&gt; &lt;port&gt;&quot;) System.exit(1) &#125; StreamingExamples.setStreamingLogLevels() // Create the context with a 1 second batch size val sparkConf = new SparkConf().setAppName(&quot;NetworkWordCount&quot;) val ssc = new StreamingContext(sparkConf, Seconds(1)) // Create a socket stream on target ip:port and count the // words in input stream of \n delimited text (eg. generated by &apos;nc&apos;) // Note that no duplication in storage level only for running locally. // Replication necessary in distributed scenario for fault tolerance. val lines = ssc.socketTextStream(args(0), args(1).toInt, StorageLevel.MEMORY_AND_DISK_SER) val words = lines.flatMap(_.split(&quot; &quot;)) val wordCounts = words.map(x =&gt; (x, 1)).reduceByKey(_ + _) wordCounts.print() ssc.start() ssc.awaitTermination() &#125;&#125;]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>SparkSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive使用教程]]></title>
    <url>%2F2018%2F09%2F27%2FHive%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[一、Hive是什么？Hive起源于Facebook，它使得针对Hadoop进行SQL查询成为可能，从而非程序员也可以方便地使用。Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的SQL查询功能，可以将SQL语句转换为MapReduce任务运行。Hive是建立在 Hadoop 上的数据仓库基础构架。它提供了一系列的工具，可以用来进行数据提取转化加载（ETL），这是一种可以存储、查询和分析存储在 Hadoop 中的大规模数据的机制。Hive 定义了简单的类 SQL 查询语言，称为 HQL，它允许熟悉 SQL 的用户查询数据。同时，这个语言也允许熟悉 MapReduce 开发者的开发自定义的 mapper 和 reducer 来处理内建的 mapper 和 reducer 无法完成的复杂的分析工作。 二、Hive工作原理（自己研究官网呗）三、Hive的安装下载hive-1.1.0-cdh5.7.0.tar.gz1wget http://archive.cloudera.com/cdh5/cdh/5/hive-1.1.0-cdh5.7.0.tar.gz 配置hive的环境变量1vim ~/.bash_profile conf/hive-env.sh配置1HADOOP_HOME=/root/app/hadoop-2.6.0-cdh5.7.0 配置hive-site.xml1234567891011121314151617181920&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://127.0.0.1:3306/hive?createDatabaseIfNotExist=true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;root&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;xbm123456&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 关键的一步拷贝mysql-connector的jar包到hive_dir/lib中1wget http://central.maven.org/maven2/mysql/mysql-connector-java/5.1.27/mysql-connector-java-5.1.27.jar 四、Hive的使用hive基本操作 1. 创建表1create table hive_wordcount(context string); 2. 加载数据到hive表12345LOAD DATA LOCAL INPATH &apos;filepath&apos; INTO TABLE tablename;load data local inpath &apos;/root/data/hehe.txt&apos; into table hive_wordcount;select word ,count(1) from hive_wordcount lateral view explode(split(context,&apos;\t&apos;)) wc as word group by word; 3. 练习12345678910111213141516171819202122create table emp( empno int, ename string, job string, mgr int, hiredate string, sal double, comm double, deptno int ) ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;\t&apos;; create table dept( deptno int, dname string, loc string )ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;\t&apos;;load data local inpath &apos;/root/data/emp.txt&apos; into table emp;load data local inpath &apos;/root/data/dept.txt&apos; into table dept;//求每个部门的人数select deptno,count(1) from emp group by deptno;]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MapReduce使用教程]]></title>
    <url>%2F2018%2F09%2F27%2FMapReduce%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[一、MapReduce是什么？ MapReduce是一个基于集群的高性能并行计算平台（Cluster Infrastructure）。它允许用市场上普通的商用服务器构成一个包含数十、数百至数千个节点的分布和并行计算集群。MapReduce是一个并行计算与运行软件框架（Software Framework）。它提供了一个庞大但设计精良的并行计算软件框架，能自动完成计算任务的并行化处理，自动划分计算数据和计算任务，在集群节点上自动分配和执行任务以及收集计算结果，将数据分布存储、数据通信、容错处理等并行计算涉及到的很多系统底层的复杂细节交由系统负责处理，大大减少了软件开发人员的负担。 二、MapReduce1.0 架构原理MapReduce程序执行流程： 解析：2.1 JobTracker:JT 作业的管理者 将作业分解成一堆的任务：Task(MapTask和ReduceTask) 将任务分派给TaskTrance运行 将任务分派给TaskTracker运行 作业的监控，容错处理（task作业挂了，重启task机制) 在一定时间间隔内，JT没有收到TT的心跳信息，TT可能是挂了，TT上运行的任务会被指派到其他的TT上去执行。 2.2 TaskTracker:TT 任务的执行者(干活的) 在TT上执行我们的Task(MapTask和ReduceTask) 会与JT进行交互：执行/启动/停止作业，发送心跳信息给JT 2.3 MapTask 自己开发的Map任务交由该Task出来，解析每条记录的数据，交给自己的map方法处理将map的输出结果写到本地磁盘（有些作业只有map没有reduce 2.4 ReduceTask 将Map Task输出的数据进行读取，按照数据进行分组传给我们自己编写的reduce方法处理，输出结果写出到hdfs 三、MapReduce2.0 架构原理 map过程： 1、map读取输入文件内容，按行解析成key1、value1键值对，key为每行首字母在文件中的偏移量，value为行的内容，每个键值对调用一次map函数；2、map根据自己逻辑，对输入的key1、value1处理，转换成新的key2、value2输出；3、对输出的key2、value2进行分区；4、对不同分区的数据，按照key2进行排序、分组，相同的key2的value放到一个集合中(中间进行复杂的shuffle过程)；5、分组后的数据进行规约； reduce过程： 1、对多个map任务的输出，按照不同的分区，通过网络copy到不同的reduce节点；2、对多个map任务的输出进行Merge(合并、排序)，根据reduce自己的任务逻辑对输入的key2、value2处理，转换成新的key3、value3输出；3、把reduce的输出保存到hdfs上； 四、MapReduce代码实例1.编写代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.Mapper;import org.apache.hadoop.mapreduce.Reducer;import java.io.IOException;/** * 用MapReduce开发一个wordcount */public class WordCountApp &#123; //ctrl看Mapper源码KEYIN, VALUEIN, KEYOUT, VALUEOUT /** * map读取输入数据 */ public static class MyMapper extends Mapper&lt;LongWritable,Text,Text,LongWritable&gt;&#123;//这里的参数前两个为输入，后两个为输出 LongWritable one = new LongWritable(1); @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123; //接收到的每一行数据 String line = value.toString(); //按规则拆分 String[] words = line.split(&quot;\t&quot;); for (String word : words) &#123; context.write(new Text(word),one); &#125; &#125; &#125; /** * 归并处理数据 */ public static class MyReducer extends Reducer&lt;Text,LongWritable,Text,LongWritable&gt;&#123; //Iterable指key的value值，也就是说如果key出现3次，那么就会key对应的values就有多个了 @Override protected void reduce(Text key, Iterable&lt;LongWritable&gt; values, Context context) throws IOException, InterruptedException &#123; long sum = 0; for (LongWritable value : values) &#123; //求key出现的总和 sum+=value.get(); &#125; //最终统计结果的输出 context.write(key,new LongWritable(sum)); &#125; &#125; public static void main(String[] args) throws Exception &#123; //创建configuration Configuration configuration = new Configuration(); //判断输出文件夹或者文件是否已经存在 Path outputPath = new Path(args[1]); FileSystem fileSystem = FileSystem.get(configuration); if (fileSystem.exists(outputPath))&#123; fileSystem.delete(outputPath,true); System.out.println(&quot;output path is exist ,but it is deleted!&quot;); &#125; //创建job Job job = Job.getInstance(configuration, &quot;wordcount&quot;); //设置job的处理类 job.setJarByClass(WordCountApp.class); //设置作业处理的输入路径 FileInputFormat.setInputPaths(job,new Path(args[0])); //设置map相关的参数 job.setMapperClass(MyMapper.class); job.setMapOutputKeyClass(Text.class); job.setMapOutputValueClass(LongWritable.class); //设置reduce相关参数 job.setReducerClass(MyReducer.class); job.setOutputKeyClass(Text.class); job.setOutputValueClass(LongWritable.class); //设置作业处理的输出路径 FileOutputFormat.setOutputPath(job,outputPath); //提交作业 System.exit(job.waitForCompletion(true)?0:1); &#125;&#125; 2.编译12//maven编译 mvn clean package -DskipTests 3.上传到服务器 可以使用xshell软件或者MobaXterm等sftp上传 4.运行1hadoop jar /root/lib/learnHdfs-1.0-SNAPSHOT.jar com.zero.mapreduce.WordCountApp hdfs://hadoop01:8020/mylove.txt hdfs://hadoop01:8020/hdfsdat/wc/]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>MapReduce</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yarn使用教程]]></title>
    <url>%2F2018%2F09%2F27%2FYarn%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[一、Yarn简介： YARN主要是将资源管理和作业监控拆分成了两个独立的服务： 1. ApplicationMaster:每个应用程序特有的，负责单个应用程序的管理。 2. ResourceManager:一个全局的资源管理器，负责整个系统的资源管理和分配。 上图解析：ResourceManager和NodeManager设计源自于数据计算框架。ResourceManager主要负责资源调度，而NodeManager是监控每一个台客户机器的cpu，内存，硬盘和网络状况，同时汇报给ResourceManager。 主要概念介绍完了，如果想看更多可移步官网 二、Yarn的安装和使用前提：Hadoop已经安装完成，可参考安装教程进入hadoop根目录，然后配置，基本上是MapReduce和yarn之间连接的配置：1vi etc/hadoop/mapred-site.xml 填入下面的配置：123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 接着1vi etc/hadoop/yarn-site.xml 填入下面的配置：123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 启动1$ sbin/start-yarn.sh 验证1http://localhost:8088/ 停止1 $ sbin/stop-yarn.sh 提交一个MapReduce作业命令：1hadoop jar /root/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0-cdh5.7.0.jar 到此Yarn搭建完成了。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Yarn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HDFS使用教程]]></title>
    <url>%2F2018%2F09%2F27%2FHDFS%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[一、HDFS的定义 HDFS含义解析：HDFS即Hadoop分布式文件系统（Hadoop Distributed Filesystem），以流式数据访问模式来存储超大文件，运行于商用硬件集群上，是管理网络中跨多台计算机存储的文件系统。 二、HDFS的适用范围 HDFS不适合用在：要求低时间延迟数据访问的应用，存储大量的小文件，多用户写入，任意修改文件。 三、HDFS的三个节点 Namenode:HDFS的守护进程，用来管理文件系统的命名空间，负责记录文件是如何分割成数据块，以及这些数据块分别被存储到那些数据节点上，它的主要功能是对内存及IO进行集中管理。 Datanode：文件系统的工作节点，根据需要存储和检索数据块，并且定期向namenode发送他们所存储的块的列表。 Secondary Namenode：辅助后台程序，与NameNode进行通信，以便定期保存HDFS元数据的快照。 四、HDFS在shell中的使用一般都是文件和文件夹的操作。123456789101112//启动hdfs$ sbin/start-dfs.sh//hdfs的shell操作： hdfs dfs -ls / --- 查看根目录下的文件 hdfs dfs -put hello.txt / --- 将本地的hello.txt提交到hdfs根目录下 hdfs dfs -text /hello.txt --- 查看hdfs目录下的hello.txt中的内容 hdfs dfs -mkdir /test --- 在hdfs中新建一个文件夹 hdfs dfs -mkdir -p /test/a/b --- 在hdfs中递归地新建文件夹 hdfs dfs -ls -R / --- 递归地查看根目录下的所有文件 hdfs dfs -copyFromLocal hello.txt /test/a/b/h.txt --- 将本地的hello.txt提交到hdfs根目录下 hdfs dfs -get /test/a/b/h.txt --- 从hdfs根目录获取h.txt到本地 hdfs dfs --- 查看帮助，基本跟Linux的命令操作一样。 五、HDFS的JavaAPI的使用 使用IDEA建立一个maven项目 1、pom.xml文件123456789101112131415161718192021222324252627282930313233343536&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.zero&lt;/groupId&gt; &lt;artifactId&gt;learnHdfs&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;name&gt;learnHdfs&lt;/name&gt; &lt;!-- FIXME change it to the project&apos;s website --&gt; &lt;url&gt;http://www.example.com&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;hadoop.version&gt;2.6.0-cdh5.7.0&lt;/hadoop.version&gt; &lt;maven.compiler.source&gt;1.7&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.7&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;cloudera&lt;/id&gt; &lt;url&gt;https://repository.cloudera.com/artifactory/cloudera-repos/&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt; &lt;version&gt;$&#123;hadoop.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2、测试JAVA类文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127package com.zero.hdfs;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.*;import org.apache.hadoop.io.IOUtils;import org.apache.hadoop.util.Progressable;import org.junit.After;import org.junit.Before;import org.junit.Test;import java.io.BufferedInputStream;import java.io.File;import java.io.FileInputStream;import java.io.InputStream;import java.net.URI;public class HDFSApp &#123; public static final String HDFS_PATH = &quot;hdfs://192.168.11.133:8020&quot;; FileSystem fileSystem = null; Configuration configuration = null; @Before public void setUp() throws Exception&#123; configuration = new Configuration(); fileSystem = FileSystem.get(new URI(HDFS_PATH),configuration,&quot;root&quot;); System.out.println(&quot;HDFSApp.setUp&quot;); &#125; /** * 创建文件夹 * @throws Exception */ @Test public void mkdir() throws Exception&#123; fileSystem.mkdirs(new Path(&quot;/hdfsdat/test&quot;)); &#125; /** * 新建文件 * @throws Exception */ @Test public void create() throws Exception&#123; FSDataOutputStream output = fileSystem.create(new Path(&quot;/hdfsdat/test/a.txt&quot;)); output.write(&quot;hello baby&quot;.getBytes()); output.flush(); output.close(); &#125; /** * 查看hdfs文件的内容 * @throws Exception */ @Test public void cat() throws Exception&#123; FSDataInputStream in = fileSystem.open(new Path(&quot;/hdfsdat/test/a.txt&quot;)); IOUtils.copyBytes(in,System.out,1024); in.close(); &#125; /** * 重命名 * @throws Exception */ @Test public void rename() throws Exception&#123; Path oldPath = new Path(&quot;/hdfsdat/test/a.txt&quot;); Path newPath = new Path(&quot;/hdfsdat/test/b.txt&quot;); fileSystem.rename(oldPath,newPath); &#125; /** * 上传文件到hdfs * @throws Exception */ @Test public void copyFromLocalFile() throws Exception&#123; Path localPath = new Path(&quot;D:/data/h.txt&quot;); Path hdfsPath = new Path(&quot;/hdfsdat/test&quot;); fileSystem.copyFromLocalFile(localPath,hdfsPath); &#125; /** * 上传大文件到hdfs，带进度条 * @throws Exception */ @Test public void copyFromLocalFileWithProgress() throws Exception&#123; InputStream in = new BufferedInputStream(new FileInputStream( new File(&quot;D:/downloads/spark-2.1.0-bin-2.6.0-cdh5.7.0.tgz&quot;) )); FSDataOutputStream output = fileSystem.create(new Path(&quot;/hdfsdat/test/spark-2.1.0-bin-2.6.0-cdh5.7.0.tgz&quot;), new Progressable() &#123; @Override public void progress() &#123; System.out.print(&quot;*&quot;);//进度提醒 &#125; &#125;); IOUtils.copyBytes(in,output,4096); &#125; /** * 下载文件到本地 * @throws Exception */ @Test public void copyTolocalFile() throws Exception&#123; Path localPath = new Path(&quot;D:/data/h.txt&quot;); Path hdfsPath = new Path(&quot;/hdfsdat/test/h.txt&quot;);// fileSystem.copyToLocalFile(hdfsPath,localPath);//会报空指针的 fileSystem.copyToLocalFile(false,hdfsPath,localPath,true); &#125; @Test public void listFiles() throws Exception &#123; FileStatus[] fileStatuses = fileSystem.listStatus(new Path(&quot;/hdfsdat/test&quot;)); for (FileStatus fileStatus: fileStatuses) &#123; String isDir = fileStatus.isDirectory()?&quot;文件夹&quot;:&quot;文件&quot;; //几个副本 short replication = fileStatus.getReplication(); //文件的大小 long len = fileStatus.getLen(); String path = fileStatus.getPath().toString(); System.out.println(isDir+&quot;\t&quot;+replication+&quot;\t&quot;+len+&quot;\t&quot;+path); &#125; &#125; @Test public void delete() throws Exception&#123; fileSystem.delete(new Path(&quot;/hdfsdat/test/a.txt&quot;),false);//第二个参数指是否递归删除 &#125; @After public void tearDown() throws Exception&#123; configuration = null; fileSystem = null; System.out.println(&quot;HDFSApp.tearDown&quot;); &#125;&#125; 如果还需了解更多可以查看官网]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>HDFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop安装教程]]></title>
    <url>%2F2018%2F09%2F27%2FHadoop%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[一、Hadoop安装需要什么呢？ 最低配置4G以上的内存，40g的硬盘是最好的(暂时可用阿里云)。 本文是基于阿里云centos7.3来搞的。所需软件安装包： hadoop-2.6.0-cdh5.7.0.tar.gz jdk-8u172-linux-x64.tar.gz 在centos中以下链接就可以下载所需的软件安装包12wget http://archive.cloudera.com/cdh5/cdh/5/hadoop-2.6.0-cdh5.7.0.tar.gzwget --no-check-certificate --no-cookies --header &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; http://download.oracle.com/otn-pub/java/jdk/8u172-b11/a58eab1ec242421181065cdc37240b08/jdk-8u172-linux-x64.tar.gz 二、安装步骤：1.安装jdk1234567891011121314151617//1.下载jdk,然后解压[root@localhost java]# tar -zxvf jdk-8u172-linux-x64.tar.gz//2.设置环境变量[root@localhost java]# vi /etc/profile//3. 在profile中添加如下内容:set java environmentJAVA_HOME=/usr/java/jdk1.7.0_79JRE_HOME=/usr/java/jdk1.7.0_79/jreCLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libPATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport JAVA_HOME JRE_HOME CLASS_PATH PATH//4.让修改生效:[root@localhost java]# source /etc/profile//5.验证JDK有效性[root@localhost java]# java -version 2.安装ssh12345678910111213[root@localhost app]# yum install sshLoaded plugins: fastestmirrorLoading mirror speeds from cached hostfile * base: mirror.bit.edu.cn * extras: mirror.bit.edu.cn * updates: mirror.bit.edu.cnNo package ssh available.Error: Nothing to do[root@localhost app]# ssh-keygen -t rsa[root@localhost app]# ll -la[root@localhost app]# cd ~/.ssh/[root@localhost app]# cp id_rsa.pub authorized_keys 3.安装hadoop12[root@localhost app]# tar -zxvf hadoop-2.6.0-cdh5.7.0.tar.gz -C ../app/[root@localhost app]# vi hadoop-2.6.0-cdh5.7.0/etc/hadoop/hadoop-env.sh hadoop-env.sh 配置：12# set to the root of your Java installation export JAVA_HOME=/root/app/jdk1.8.0_172 hosts文件 配置： vi /etc/hosts1192.168.11.133 hadoop01 特别注意这里：(如果是阿里云上部署的是填写内网ip的，不是外网的那个)4.hadoop两个最重要的配置文件 在hadoop的根目录 123456789101112131415161718192021 [root@localhost hadoop]# vi etc/hadoop/core-site.xml// core-site.xml配置：&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://hadoop01:8020&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; [root@localhost hadoop]# vi etc/hadoop/hdfs-site.xml//修改hdfs-site.xml配置：&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.http.address&lt;/name&gt; &lt;value&gt;hadoop01:50070&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 5.启动：123456789101112131415//安装的时候，只执行一次，格式化文件系统[root@localhost hadoop]# bin/hdfs namenode -Format //1.启动hdfs：[root@localhost hadoop]# sbin/start-dfs.sh//2.验证是否启动成功 浏览器访问 http://[你的IP]:50070 或者 命令： jps NameNode DataNode SecondaryNameNode//3.停止hdfs ./stop-dfs.sh//4.配置hadoop快捷方式跟java的配置一样vi /etc/profileHADOOP_HOME=/root/app/hadoop-2.6.0-cdh5.7.0]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据概述]]></title>
    <url>%2F2018%2F09%2F27%2F%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[一、大数据之hadoop 学习框架最简单快捷的方法是看官网：http://hadoop.apache.org/ Hadoop是一个框架，它可以允许分布式处理大数据集可以用简单工程模式实现计算机集群。它涉及有一个简单服务器转换成千上万机器，每一个本地计算和存储。然而硬件传送高可用，框架自己可以监测和处理错误在应用层，所以传送高可用服务在计算机集群。 Hadoop项目主要包括以下几个模块： 1、hadoop通用模块:这是一个通用工具支持其他hadoop的模块。2、HDFS：一个分布式文件系统，它提供高流量传递应用数据。3、YARN:一个工作调度和资源管理的框架。4、MapReduce:一个基于YARN之上的并行计算大数据集的计算框架。 二、Hadoop之HDFSHDFS是一个主要的hadoop应用常用的分布式存储系统。一个HDFS主要包括一个NameNode和多个DataNodes。 1、NameNode是负责管理文件系统元数据，2、DataNodes是存储真实的数据的 三、Hadoop之YARNYARN是Hadoop 2.0中的资源管理系统，它的基本设计思想是将MRv1中的JobTracker拆分成了两个独立的服务： 1、ResourceManager负责整个系统的资源管理和分配2、ApplicationMaster负责单个应用程序的管理。 四、Hadoop之MapReduceMapReduce是一个可以在可靠的，有容错性大数据集群上面并行的进行逻辑计算的计算框架。 一个MapReduce的作业通常分为输入数据集到独立原型，它可以处理map任务在完整的并行方法。它也可以对maps的输出进行排序，然后减少任务。通常地输入和输出作业是被存储到文件系统。它主要关注的是计划的任务和监控这些任务，如果任务失败了就重启这些任务。 通常地，计算节点和存储节点都是相同的，MapReduce框架和hdfs是运行在相同的节点上的。者配置可以使框架有效地安排任务在以前的数据在这个节点上，计算结果通过带宽整合到集群上。 MapReduce包含一个单主节点ResourceManager和一个从节点NodeManager ，按每一个应用都有的MRAppMaster最低限度，应用需要输入和输出位置和提供map方法和reduce方法实现接口或者抽象方法。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo+GitHub搭建个人博客]]></title>
    <url>%2F2018%2F09%2F26%2FHexo-blog%2F</url>
    <content type="text"><![CDATA[一、安装Hexo 安装node.js 、git 安装Hexo,打开控制台cmd,输入命令： npm install -g hexo-cli 二、初始化 找个空文件夹，打开终端，输入以下命令： 1234hexo i blog //初始化cd blog //切换到项目根目录hexo g //生成页面hexo s //运行server 打开浏览器输入localhost:4000查看到以下页面 三、修改主题-nexT blog的根目录下运行命令 1git clone https://github.com/iissnan/hexo-theme-next themes/next 修改配置_config.yml文件 1theme: next 修改主题 在 站点根目录/themes/next/_congig.yml 文件中修改 12345# Schemes# scheme: Musescheme: Mist# scheme: Pisces# scheme: Gemini 运行命令 12345hexo clean //清缓存hexo g //重新编译生成代码hexo s //部署到本地//然后打开浏览器访问 localhost:4000 查看效果 四、上传到GitHub 你的GitHub中新建一个repository，项目名称格式： 为：你的账号名.github.io 修改hexo站点的配置文件_config.yml，找到最后，加入第一步的那个项目地址。格式最好复制过去改，因为这里很狗血的。 1234deploy: type: git repository: https://github.com/你的账号/你的账号.github.io.git branch: master 部署到GitHub中 12npm install hexo-deployer-git --save //安装插件hexo d // 部署的命令 五、配置域名 如果你有的话也可以配置，腾讯云的比较便宜，不过域名要备案的 根目录/source 目录下创建一个新文件CNAME 将域名添加进去 运行命令123hexo clean //清缓存hexo g //重新编译生成代码hexo d //部署到github 六、发布自己文章 在blog根目录\source_posts中有.md的文件模板 然后你可以写好.md文件之后，运行hexo clean、hexo g、hexo d 进行发布。 所以修改模板的名字这些操作可以全局搜索，相应的关键词进行替换就可以修改成你自己的名字了。_config.yml文件中可以修改作者和blog的名称之类的配置。 七、后记感谢这位大哥的指引 https://blog.csdn.net/Hoshea_chx/article/details/78826689]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>Blog</tag>
      </tags>
  </entry>
</search>
